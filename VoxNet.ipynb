{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3011BOir0HoQpnRDs3FMZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tabba98/neural-network/blob/main/VoxNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nz0WALPw5LNa",
        "outputId": "889283f4-a6b1-4dde-df4f-711b69457a42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.0+cu116)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.0\n"
          ]
        }
      ],
      "source": [
        "pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchmetrics.classification import Accuracy\n",
        "from torchmetrics import ConfusionMatrix\n",
        "\n",
        "\n",
        "\n",
        "#for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import scipy\n",
        "from scipy.ndimage import rotate\n",
        "\n",
        "import time"
      ],
      "metadata": {
        "id": "Ic3yD5Ks5Stj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget https://www.dropbox.com/s/ja56cvf3x4mkf1t/modelnet10_voxelized_32.npz"
      ],
      "metadata": {
        "id": "BGBFL8fX5Uuv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VoxelDataset(Dataset):\n",
        "    def __init__(self, train = True):\n",
        "      if train:\n",
        "          tmp = np.load(\"modelnet10_voxelized_32.npz\")\n",
        "          self.data = tmp[\"X_train\"]\n",
        "          self.label = tmp[\"Y_train\"]\n",
        "          del tmp\n",
        "      else:\n",
        "          tmp = np.load(\"modelnet10_voxelized_32.npz\")\n",
        "          self.data = tmp[\"X_test\"]\n",
        "          self.label = tmp[\"Y_test\"]\n",
        "          del tmp\n",
        "        \n",
        "                \n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "\n",
        "    def __preproc__(self, voxels):\n",
        "        \n",
        "        #flip x\n",
        "        if np.random.randint(2):\n",
        "            voxels = np.flip(voxels, axis=0)\n",
        "        \n",
        "        #flip y\n",
        "        if np.random.randint(2):\n",
        "            voxels = np.flip(voxels, axis=1)\n",
        "        \n",
        "        angle = 360 * np.random.random_sample(1)[0]\n",
        "        \n",
        "        voxels = rotate(voxels, axes=(0, 1), angle=angle, cval=0.0, reshape=False)\n",
        "        \n",
        "        \n",
        "        return voxels.copy()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.label[idx]\n",
        "        voxels = self.data[idx]\n",
        "        voxels = self.__preproc__(voxels)\n",
        "        voxels = np.expand_dims(voxels, axis=0)\n",
        "        voxels = torch.tensor(voxels).float()\n",
        "        return voxels, label"
      ],
      "metadata": {
        "id": "pfSGCV6k5YXr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "class VoxNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VoxNet, self).__init__()\n",
        "        n_classes = 10\n",
        "        input_shape = (32,32,32)\n",
        "        self.feat = torch.nn.Sequential(OrderedDict([\n",
        "            ('conv3d_1', torch.nn.Conv3d(in_channels=1, out_channels=32, kernel_size=5, stride=2)),\n",
        "            ('relu1', torch.nn.ReLU()),\n",
        "            ('drop1', torch.nn.Dropout(p=0.2)),\n",
        "            ('conv3d_2', torch.nn.Conv3d(in_channels=32, out_channels=32, kernel_size=3)),\n",
        "            ('relu2', torch.nn.ReLU()),\n",
        "            ('pool2', torch.nn.MaxPool3d(2)),\n",
        "            ('drop2', torch.nn.Dropout(p=0.3))\n",
        "        ]))\n",
        "        \n",
        "        x = self.feat(torch.autograd.Variable(torch.rand((1, 1) + input_shape)))\n",
        "        dim_feat = 1\n",
        "        for n in x.size()[1:]:\n",
        "            dim_feat *= n\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(OrderedDict([\n",
        "            ('fc1', torch.nn.Linear(dim_feat, 128)),\n",
        "            ('relu1', torch.nn.ReLU()),\n",
        "            ('drop3', torch.nn.Dropout(p=0.4)),\n",
        "            ('fc2', torch.nn.Linear(128, n_classes))\n",
        "        ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feat(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.mlp(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "BxJn-rxg5thp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import SGD, Adam\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from tqdm import tqdm\n",
        "\n",
        "def blue(x): return '\\033[94m' + x + '\\033[0m'\n",
        "\n",
        "train_ds = VoxelDataset(train=True)\n",
        "test_ds = VoxelDataset(train=False)\n",
        "train_dataloader = DataLoader(dataset=train_ds, batch_size=32, shuffle=True, drop_last=True)\n",
        "test_dataloader = DataLoader(dataset=test_ds, batch_size=32)\n",
        "\n",
        "model = VoxNet()\n",
        "opt = SGD(model.parameters(), lr=1e-2, weight_decay = 0)\n",
        "loss_fn = F.cross_entropy\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "epochs=10\n",
        "best_val = np.inf\n",
        "\n",
        "num_batch = len(train_ds) / 32\n",
        "print(num_batch)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    temp_correct = 0\n",
        "    temp_testset = 0\n",
        "    temp_correct_test = 0\n",
        "    temp_testset_test = 0\n",
        "    for i, data in tqdm(enumerate(train_dataloader, 0)):\n",
        "        inputs, labels = data[0], data[1]\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # 梯度清零\n",
        "        opt.zero_grad()\n",
        "\n",
        "        # 网络切换训练模型\n",
        "        voxnet = model.train()\n",
        "        pred = voxnet(inputs)  # torch.Size([256, 10])\n",
        "\n",
        "        # 计算损失函数\n",
        "\n",
        "        loss = F.cross_entropy(pred,labels)\n",
        "\n",
        "        # 反向传播, 更新权重\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        # 计算该batch的预测准确率\n",
        "        pred_choice = pred.data.max(1)[1]\n",
        "        correct = pred_choice.eq(labels.data).cpu().sum()\n",
        "        #print('[%d: %d/%d] train loss: %f accuracy: %f' % (epoch, i+1, num_batch, loss.item(), correct.item() / 32))\n",
        "        temp_correct += correct.item()\n",
        "        temp_testset += inputs.size()[0]\n",
        "        \n",
        "    \n",
        "    for j, sample in tqdm(enumerate(test_dataloader, 0)):    \n",
        "        inputs_test, labels_test = sample[0], sample[1]\n",
        "        inputs_test = inputs_test.to(device)\n",
        "        labels_test = labels_test.to(device)\n",
        "        inputs_test = inputs_test.float()  # 转float, torch.Size([256, 1, 32, 32, 32])\n",
        "        voxnet = voxnet.eval()\n",
        "        pred_test = voxnet(inputs_test)\n",
        "        loss_test = F.nll_loss(pred_test, labels_test)\n",
        "        pred_choice_test = pred_test.data.max(1)[1]\n",
        "        correct_test = pred_choice_test.eq(labels_test.data).cpu().sum()\n",
        "        \n",
        "        temp_correct_test += correct_test.item()\n",
        "        temp_testset_test += inputs_test.size()[0]\n",
        "    \n",
        "    print(\"epoch %d: train accuracy %f\" % (epoch, temp_correct / float(temp_testset)))\n",
        "    print(\"epoch %d: test accuracy %f\" % (epoch, temp_correct_test / float(temp_testset_test)))\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "total_correct = 0\n",
        "total_testset = 0\n",
        "\n",
        "for i, data in tqdm(enumerate(test_dataloader, 0)):\n",
        "    inputs, labels = data[0], data[1]\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    inputs = inputs.float()  # 转float, torch.Size([256, 1, 32, 32, 32])\n",
        "\n",
        "    voxnet = voxnet.eval()\n",
        "    pred = voxnet(inputs)\n",
        "    pred_choice = pred.data.max(1)[1]\n",
        "    correct = pred_choice.eq(labels.data).cpu().sum()\n",
        "    total_correct += correct.item()\n",
        "    total_testset += inputs.size()[0]\n",
        "\n",
        "print(\"final accuracy {}\".format(total_correct / float(total_testset)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oa5xA1t7kzU",
        "outputId": "28c95d4b-009d-4f5e-a2bb-a13f14a0f480"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "124.71875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "124it [01:08,  1.81it/s]\n",
            "29it [00:08,  3.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 train accuracy 0.355595\n",
            "epoch 0 test accuracy 0.549559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "124it [01:11,  1.72it/s]\n",
            "29it [00:08,  3.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 train accuracy 0.623740\n",
            "epoch 1 test accuracy 0.674009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "124it [01:09,  1.79it/s]\n",
            "29it [00:08,  3.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 train accuracy 0.686240\n",
            "epoch 2 test accuracy 0.688326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "124it [01:08,  1.80it/s]\n",
            "29it [00:08,  3.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 train accuracy 0.724042\n",
            "epoch 3 test accuracy 0.719163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "124it [01:10,  1.76it/s]\n",
            "29it [00:08,  3.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 train accuracy 0.756804\n",
            "epoch 4 test accuracy 0.753304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "124it [01:09,  1.77it/s]\n",
            "29it [00:08,  3.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 train accuracy 0.773942\n",
            "epoch 5 test accuracy 0.776432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "124it [01:10,  1.77it/s]\n",
            "29it [00:09,  3.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6 train accuracy 0.786542\n",
            "epoch 6 test accuracy 0.779736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "124it [01:10,  1.75it/s]\n",
            "29it [00:08,  3.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7 train accuracy 0.803427\n",
            "epoch 7 test accuracy 0.756608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "124it [01:10,  1.77it/s]\n",
            "29it [00:08,  3.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8 train accuracy 0.811240\n",
            "epoch 8 test accuracy 0.805066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "124it [01:10,  1.77it/s]\n",
            "29it [00:08,  3.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9 train accuracy 0.824345\n",
            "epoch 9 test accuracy 0.818282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "29it [00:08,  3.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final accuracy 0.8105726872246696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ng_DWo2tDoIF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}