{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBXg9CGD7bxVXnm0BGWhuW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tabba98/neural-network/blob/main/VoxNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the Libraries"
      ],
      "metadata": {
        "id": "vV-7Y3QXDnGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "!pip install torchmetrics\n",
        "from torchmetrics.classification import Accuracy\n",
        "from torchmetrics import ConfusionMatrix\n",
        "\n",
        "!pip install open3d;\n",
        "import open3d as o3d\n",
        "\n",
        "#for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import scipy\n",
        "from scipy.ndimage import rotate\n",
        "\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "!pip install Pillow==9.0"
      ],
      "metadata": {
        "id": "Ic3yD5Ks5Stj",
        "outputId": "6a72c007-3782-474d-b669-46f9d392958c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 KB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting open3d\n",
            "  Downloading open3d-0.17.0-cp39-cp39-manylinux_2_27_x86_64.whl (420.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m420.5/420.5 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.9/dist-packages (from open3d) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.9/dist-packages (from open3d) (1.2.2)\n",
            "Collecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: werkzeug>=2.2.3 in /usr/local/lib/python3.9/dist-packages (from open3d) (2.2.3)\n",
            "Collecting pillow>=9.3.0\n",
            "  Downloading Pillow-9.4.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipywidgets>=8.0.4\n",
            "  Downloading ipywidgets-8.0.5-py3-none-any.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 KB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nbformat==5.7.0\n",
            "  Downloading nbformat-5.7.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 KB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dash>=2.6.0\n",
            "  Downloading dash-2.9.1-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting configargparse\n",
            "  Downloading ConfigArgParse-1.5.3-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.9/dist-packages (from open3d) (3.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from open3d) (4.65.0)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.9/dist-packages (from open3d) (1.4.4)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.9/dist-packages (from open3d) (6.0)\n",
            "Collecting pyquaternion\n",
            "  Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.9/dist-packages (from nbformat==5.7.0->open3d) (5.3.0)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.9/dist-packages (from nbformat==5.7.0->open3d) (5.7.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.9/dist-packages (from nbformat==5.7.0->open3d) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.9/dist-packages (from nbformat==5.7.0->open3d) (2.16.3)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from dash>=2.6.0->open3d) (5.13.1)\n",
            "Collecting dash-table==5.0.0\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Collecting dash-html-components==2.0.0\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Collecting dash-core-components==2.0.0\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: Flask>=1.0.4 in /usr/local/lib/python3.9/dist-packages (from dash>=2.6.0->open3d) (2.2.3)\n",
            "Collecting widgetsnbextension~=4.0\n",
            "  Downloading widgetsnbextension-4.0.6-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets>=8.0.4->open3d) (7.9.0)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3->open3d) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3->open3d) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3->open3d) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3->open3d) (5.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3->open3d) (23.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3->open3d) (4.39.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3->open3d) (1.0.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3->open3d) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0->open3d) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21->open3d) (1.1.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21->open3d) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21->open3d) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=2.2.3->open3d) (2.1.2)\n",
            "Requirement already satisfied: importlib-metadata>=3.6.0 in /usr/local/lib/python3.9/dist-packages (from Flask>=1.0.4->dash>=2.6.0->open3d) (6.1.0)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.9/dist-packages (from Flask>=1.0.4->dash>=2.6.0->open3d) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.9/dist-packages (from Flask>=1.0.4->dash>=2.6.0->open3d) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.9/dist-packages (from Flask>=1.0.4->dash>=2.6.0->open3d) (8.1.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3->open3d) (3.15.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.9/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (67.6.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.9/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat==5.7.0->open3d) (22.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat==5.7.0->open3d) (0.19.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (8.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib>=3->open3d) (1.16.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.9/dist-packages (from jupyter-core->nbformat==5.7.0->open3d) (3.1.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.10->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n",
            "Installing collected packages: dash-table, dash-html-components, dash-core-components, addict, widgetsnbextension, pyquaternion, pillow, jedi, configargparse, nbformat, ipywidgets, dash, open3d\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.3\n",
            "    Uninstalling widgetsnbextension-3.6.3:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.3\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 8.4.0\n",
            "    Uninstalling Pillow-8.4.0:\n",
            "      Successfully uninstalled Pillow-8.4.0\n",
            "  Attempting uninstall: nbformat\n",
            "    Found existing installation: nbformat 5.8.0\n",
            "    Uninstalling nbformat-5.8.0:\n",
            "      Successfully uninstalled nbformat-5.8.0\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed addict-2.4.0 configargparse-1.5.3 dash-2.9.1 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 ipywidgets-8.0.5 jedi-0.18.2 nbformat-5.7.0 open3d-0.17.0 pillow-9.4.0 pyquaternion-0.9.9 widgetsnbextension-4.0.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "ipywidgets"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Pillow==9.0\n",
            "  Downloading Pillow-9.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "open3d 0.17.0 requires pillow>=9.3.0, but you have pillow 9.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-9.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download and unzip the dataset ModelNet10"
      ],
      "metadata": {
        "id": "cGpYL7odDvTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip"
      ],
      "metadata": {
        "id": "BGBFL8fX5Uuv",
        "outputId": "2a276bc0-d878-436e-8b7b-f8e7d3aac464",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-24 11:40:51--  http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\n",
            "Resolving 3dvision.princeton.edu (3dvision.princeton.edu)... 128.112.136.74\n",
            "Connecting to 3dvision.princeton.edu (3dvision.princeton.edu)|128.112.136.74|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip [following]\n",
            "--2023-03-24 11:40:51--  https://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\n",
            "Connecting to 3dvision.princeton.edu (3dvision.princeton.edu)|128.112.136.74|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 473402300 (451M) [application/zip]\n",
            "Saving to: ‘ModelNet10.zip’\n",
            "\n",
            "ModelNet10.zip      100%[===================>] 451.47M  85.5MB/s    in 5.0s    \n",
            "\n",
            "2023-03-24 11:40:56 (90.7 MB/s) - ‘ModelNet10.zip’ saved [473402300/473402300]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q ModelNet10.zip;"
      ],
      "metadata": {
        "id": "06P5PcU8L_Xq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Voxelization of the off. files in dataset"
      ],
      "metadata": {
        "id": "Fqc2ykibD5DP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "\n",
        "ROOT = '/content/ModelNet10/'\n",
        "CLASSES = ['bathtub', 'bed', 'chair', 'desk', 'dresser', 'monitor', 'night_stand', 'sofa', 'table', 'toilet']\n",
        "ROTATIONS = ['0', '45', '90', '135', '180', '225', '270', '315']\n",
        "\n",
        "#rotations matrix\n",
        "r45 = np.array([[math.sqrt(2)/2,-math.sqrt(2)/2,0], [math.sqrt(2)/2,math.sqrt(2)/2,0], [0,0,1]], np.float64)\n",
        "r90 = np.array([[0,-1,0], [1,0,0], [0,0,1]], np.float64)\n",
        "r135 = np.array([[-math.sqrt(2)/2,-math.sqrt(2)/2,0], [math.sqrt(2)/2,-math.sqrt(2)/2,0], [0,0,1]], np.float64)\n",
        "r180 = np.array([[-1,0,0], [0,-1,0], [0,0,1]], np.float64)\n",
        "r225 = np.array([[-math.sqrt(2)/2,math.sqrt(2)/2,0], [-math.sqrt(2)/2,-math.sqrt(2)/2,0], [0,0,1]], np.float64)\n",
        "r270 = np.array([[0,1,0], [-1,0,0], [0,0,1]], np.float64)\n",
        "r315 = np.array([[math.sqrt(2)/2,math.sqrt(2)/2,0], [-math.sqrt(2)/2,math.sqrt(2)/2,0], [0,0,1]], np.float64)\n",
        "\n",
        "X = {'train': [], 'test': []}\n",
        "Y = {'train': [], 'test': []}\n",
        "Z = {'train': [], 'test': []}\n",
        "\n",
        "for label1, cl in enumerate(CLASSES):\n",
        "    for label2, rot in enumerate(ROTATIONS):\n",
        "        split = 'train'\n",
        "        examples_dir = os.path.join(ROOT, cl, split)\n",
        "        for example in tqdm(os.listdir(examples_dir)[:100]):\n",
        "            voxel_index = []\n",
        "            if 'off' in example:\n",
        "              mesh = o3d.io.read_triangle_mesh(examples_dir+'/'+example)\n",
        "              if rot == '0':\n",
        "                mesh = mesh\n",
        "              elif rot == '45':\n",
        "                mesh.rotate(r45)\n",
        "              elif rot == '90':\n",
        "                mesh.rotate(r90)\n",
        "              elif rot == '135':\n",
        "                mesh.rotate(r135)  \n",
        "              elif rot == '180':\n",
        "                mesh.rotate(r180)\n",
        "              elif rot == '225':\n",
        "                mesh.rotate(r225)\n",
        "              elif rot == '270':\n",
        "                mesh.rotate(r270)\n",
        "              else:\n",
        "                mesh.rotate(r315)\n",
        "        \n",
        "              mesh.scale(1 / np.max(mesh.get_max_bound() - mesh.get_min_bound()), center=mesh.get_center())\n",
        "              voxel_grid = o3d.geometry.VoxelGrid.create_from_triangle_mesh(mesh, voxel_size=0.05)\n",
        "                \n",
        "            X[split].append(voxel_grid)\n",
        "            Y[split].append(label1)\n",
        "            Z[split].append(label2)\n",
        "\n",
        "for label1, cl in enumerate(CLASSES):\n",
        "    for label2, rot in enumerate(ROTATIONS):\n",
        "        split = 'test'\n",
        "        examples_dir = os.path.join(ROOT, cl, split)\n",
        "        for example in tqdm(os.listdir(examples_dir)[:50]):\n",
        "            voxel_index = []\n",
        "            if 'off' in example:\n",
        "              mesh = o3d.io.read_triangle_mesh(examples_dir+'/'+example)\n",
        "              if rot == '0':\n",
        "                mesh = mesh\n",
        "              elif rot == '45':\n",
        "                mesh.rotate(r45)\n",
        "              elif rot == '90':\n",
        "                mesh.rotate(r90)\n",
        "              elif rot == '135':\n",
        "                mesh.rotate(r135)  \n",
        "              elif rot == '180':\n",
        "                mesh.rotate(r180)\n",
        "              elif rot == '225':\n",
        "                mesh.rotate(r225)\n",
        "              elif rot == '270':\n",
        "                mesh.rotate(r270)\n",
        "              else:\n",
        "                mesh.rotate(r315)\n",
        "\n",
        "              mesh.scale(1 / np.max(mesh.get_max_bound() - mesh.get_min_bound()), center=mesh.get_center())\n",
        "              voxel_grid = o3d.geometry.VoxelGrid.create_from_triangle_mesh(mesh, voxel_size=0.05)\n",
        "                \n",
        "            X[split].append(voxel_grid)\n",
        "            Y[split].append(label1)\n",
        "            Z[split].append(label2)\n"
      ],
      "metadata": {
        "id": "q-fFm_XKMDMH",
        "outputId": "45078e1e-1ead-4a43-d9b1-538868dfe119",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 24.47it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 31.90it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 37.51it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 35.56it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 32.15it/s]\n",
            "100%|██████████| 100/100 [00:04<00:00, 24.41it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 36.62it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 35.16it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 29.32it/s]\n",
            "100%|██████████| 100/100 [00:04<00:00, 20.62it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 30.03it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 30.07it/s]\n",
            "100%|██████████| 100/100 [00:04<00:00, 21.30it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 27.83it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 30.70it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 29.70it/s]\n",
            "100%|██████████| 100/100 [00:05<00:00, 18.17it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 25.30it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 25.99it/s]\n",
            "100%|██████████| 100/100 [00:05<00:00, 17.83it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 25.78it/s]\n",
            "100%|██████████| 100/100 [00:04<00:00, 24.94it/s]\n",
            "100%|██████████| 100/100 [00:05<00:00, 18.07it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 25.46it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 44.11it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 27.09it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 31.11it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 40.21it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 42.84it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 41.32it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 32.13it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 29.94it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 36.13it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 33.92it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 35.96it/s]\n",
            "100%|██████████| 100/100 [00:04<00:00, 21.82it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 35.40it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 33.61it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 36.04it/s]\n",
            "100%|██████████| 100/100 [00:04<00:00, 21.41it/s]\n",
            "100%|██████████| 100/100 [00:00<00:00, 117.60it/s]\n",
            "100%|██████████| 100/100 [00:01<00:00, 95.74it/s]\n",
            "100%|██████████| 100/100 [00:00<00:00, 121.71it/s]\n",
            "100%|██████████| 100/100 [00:01<00:00, 94.80it/s]\n",
            "100%|██████████| 100/100 [00:00<00:00, 120.41it/s]\n",
            "100%|██████████| 100/100 [00:01<00:00, 95.95it/s]\n",
            "100%|██████████| 100/100 [00:00<00:00, 123.68it/s]\n",
            "100%|██████████| 100/100 [00:01<00:00, 96.36it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 39.25it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 27.99it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 46.17it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 43.31it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 45.93it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 44.23it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 26.41it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 42.35it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 36.42it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 34.57it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 28.83it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 26.05it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 36.52it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 34.56it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 33.55it/s]\n",
            "100%|██████████| 100/100 [00:04<00:00, 23.15it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 37.04it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 35.67it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 31.35it/s]\n",
            "100%|██████████| 100/100 [00:04<00:00, 22.77it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 37.80it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 36.00it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 37.07it/s]\n",
            "100%|██████████| 100/100 [00:04<00:00, 22.79it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 28.75it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 28.44it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 25.55it/s]\n",
            "100%|██████████| 100/100 [00:04<00:00, 20.71it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 28.91it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 27.87it/s]\n",
            "100%|██████████| 100/100 [00:05<00:00, 19.60it/s]\n",
            "100%|██████████| 100/100 [00:03<00:00, 27.99it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 40.20it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 40.21it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 41.06it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 40.43it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 31.25it/s]\n",
            "100%|██████████| 50/50 [00:02<00:00, 20.76it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 37.92it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 40.05it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 35.16it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 33.58it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 35.20it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 33.99it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 36.41it/s]\n",
            "100%|██████████| 50/50 [00:02<00:00, 20.19it/s]\n",
            "100%|██████████| 50/50 [00:02<00:00, 23.84it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 34.66it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 30.72it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 29.71it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 30.48it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 29.78it/s]\n",
            "100%|██████████| 50/50 [00:02<00:00, 24.99it/s]\n",
            "100%|██████████| 50/50 [00:03<00:00, 16.66it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 29.38it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 29.36it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 56.22it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 53.08it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 56.42it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 53.55it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 55.57it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 51.75it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 51.15it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 27.30it/s]\n",
            "100%|██████████| 50/50 [00:02<00:00, 23.82it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 31.62it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 34.19it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 31.33it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 26.23it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 32.36it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 30.93it/s]\n",
            "100%|██████████| 50/50 [00:02<00:00, 17.02it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 108.78it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 97.27it/s] \n",
            "100%|██████████| 50/50 [00:00<00:00, 127.81it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 94.05it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 120.71it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 96.42it/s] \n",
            "100%|██████████| 50/50 [00:00<00:00, 127.15it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 90.51it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 112.30it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 96.10it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 108.12it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 98.09it/s] \n",
            "100%|██████████| 50/50 [00:00<00:00, 110.57it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 99.70it/s] \n",
            "100%|██████████| 50/50 [00:00<00:00, 117.12it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 96.00it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 32.48it/s]\n",
            "100%|██████████| 50/50 [00:02<00:00, 21.33it/s]\n",
            "100%|██████████| 50/50 [00:02<00:00, 19.85it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 30.78it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 32.13it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 29.65it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 33.33it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 30.96it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 87.53it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 81.44it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 64.81it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 41.46it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 47.06it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 52.89it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 86.70it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 77.93it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 26.76it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 25.77it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 26.14it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 25.62it/s]\n",
            "100%|██████████| 50/50 [00:02<00:00, 18.17it/s]\n",
            "100%|██████████| 50/50 [00:02<00:00, 18.47it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 26.69it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 25.77it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "\n",
        "ROOT = '/content/ModelNet10/'\n",
        "CLASSES = ['bathtub', 'bed', 'chair', 'desk', 'dresser', 'monitor', 'night_stand', 'sofa', 'table', 'toilet']\n",
        "ROTATIONS = ['0', '45', '90', '135', '180', '225', '270', '315']\n",
        "\n",
        "#rotations matrix\n",
        "r45 = np.array([[math.sqrt(2)/2,-math.sqrt(2)/2,0], [math.sqrt(2)/2,math.sqrt(2)/2,0], [0,0,1]], np.float64)\n",
        "r90 = np.array([[0,-1,0], [1,0,0], [0,0,1]], np.float64)\n",
        "r135 = np.array([[-math.sqrt(2)/2,-math.sqrt(2)/2,0], [math.sqrt(2)/2,-math.sqrt(2)/2,0], [0,0,1]], np.float64)\n",
        "r180 = np.array([[-1,0,0], [0,-1,0], [0,0,1]], np.float64)\n",
        "r225 = np.array([[-math.sqrt(2)/2,math.sqrt(2)/2,0], [-math.sqrt(2)/2,-math.sqrt(2)/2,0], [0,0,1]], np.float64)\n",
        "r270 = np.array([[0,1,0], [-1,0,0], [0,0,1]], np.float64)\n",
        "r315 = np.array([[math.sqrt(2)/2,math.sqrt(2)/2,0], [-math.sqrt(2)/2,math.sqrt(2)/2,0], [0,0,1]], np.float64)\n",
        "\n",
        "X = {'train': [], 'test': []}\n",
        "Y = {'train': [], 'test': []}\n",
        "Z = {'train': [], 'test': []}\n",
        "\n",
        "for label, cl in enumerate(CLASSES):\n",
        "    for split in ['train', 'test']:\n",
        "        examples_dir = os.path.join(ROOT, cl, split)\n",
        "        for example in tqdm(os.listdir(examples_dir)):\n",
        "          voxel_index = []\n",
        "          rot = random.choice(ROTATIONS)\n",
        "          if 'off' in example:\n",
        "            mesh = o3d.io.read_triangle_mesh(examples_dir+'/'+example)\n",
        "            if rot == '0':\n",
        "              mesh = mesh\n",
        "              rotat = 0\n",
        "            elif rot == '45':\n",
        "              mesh.rotate(r45)\n",
        "              rotat = 1\n",
        "            elif rot == '90':\n",
        "              mesh.rotate(r90)\n",
        "              rotat = 2\n",
        "            elif rot == '135':\n",
        "              mesh.rotate(r135) \n",
        "              rotat = 3 \n",
        "            elif rot == '180':\n",
        "              mesh.rotate(r180)\n",
        "              rotat = 4\n",
        "            elif rot == '225':\n",
        "              mesh.rotate(r225)\n",
        "              rotat = 5\n",
        "            elif rot == '270':\n",
        "              mesh.rotate(r270)\n",
        "              rotat = 6\n",
        "            else:\n",
        "              mesh.rotate(r315)\n",
        "              rotat = 7\n",
        "            mesh.scale(1 / np.max(mesh.get_max_bound() - mesh.get_min_bound()), center=mesh.get_center())\n",
        "            voxel_grid = o3d.geometry.VoxelGrid.create_from_triangle_mesh(mesh, voxel_size=0.05)\n",
        "            \n",
        "            X[split].append(voxel_grid)\n",
        "            Y[split].append(label)\n",
        "            Z[split].append(rotat)"
      ],
      "metadata": {
        "id": "V2RlX3XWaDz2",
        "outputId": "9a212a58-2037-4147-af16-7ea512cae382",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 106/106 [00:04<00:00, 21.73it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 37.44it/s]\n",
            "100%|██████████| 516/516 [00:20<00:00, 25.25it/s]\n",
            "100%|██████████| 101/101 [00:04<00:00, 22.74it/s]\n",
            "100%|██████████| 890/890 [00:40<00:00, 21.82it/s]\n",
            "100%|██████████| 101/101 [00:04<00:00, 22.45it/s]\n",
            "100%|██████████| 200/200 [00:04<00:00, 46.51it/s]\n",
            "100%|██████████| 86/86 [00:01<00:00, 53.30it/s]\n",
            "100%|██████████| 200/200 [00:08<00:00, 24.14it/s]\n",
            "100%|██████████| 86/86 [00:02<00:00, 35.44it/s]\n",
            "100%|██████████| 465/465 [00:08<00:00, 54.77it/s]\n",
            "100%|██████████| 100/100 [00:01<00:00, 80.84it/s]\n",
            "100%|██████████| 200/200 [00:03<00:00, 58.34it/s]\n",
            "100%|██████████| 86/86 [00:01<00:00, 56.32it/s]\n",
            "100%|██████████| 680/680 [00:31<00:00, 21.37it/s]\n",
            "100%|██████████| 100/100 [00:05<00:00, 19.15it/s]\n",
            "100%|██████████| 392/392 [00:10<00:00, 37.46it/s]\n",
            "100%|██████████| 100/100 [00:01<00:00, 57.37it/s]\n",
            "100%|██████████| 345/345 [00:13<00:00, 24.98it/s]\n",
            "100%|██████████| 101/101 [00:04<00:00, 24.56it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mesh = o3d.io.read_triangle_mesh('/content/ModelNet10/chair/train/chair_0003.off')\n",
        "mesh.rotate(r315)\n",
        "              \n",
        "mesh.scale(1 / np.max(mesh.get_max_bound() - mesh.get_min_bound()), center=mesh.get_center())\n",
        "voxel_grid = o3d.geometry.VoxelGrid.create_from_triangle_mesh(mesh, voxel_size=0.05)\n",
        "\n",
        "vox_grid = voxel_grid.get_voxels()\n",
        "vox_g = np.zeros((32, 32, 32), dtype=np.int32)\n",
        "for i in range (len(vox_grid)):\n",
        "  voxel_index = vox_grid[i].grid_index\n",
        "  vox_g[voxel_index[0],voxel_index[1],voxel_index[2]] = 1\n",
        "\n",
        "\n",
        "ax = plt.figure(figsize=(10,10)).add_subplot(projection='3d')\n",
        "ax.voxels(vox_g, edgecolor='k')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PfviN0ozYvVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset setup and Trainer"
      ],
      "metadata": {
        "id": "NDE8PhnsECNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VoxelDataset(Dataset):\n",
        "    def __init__(self, train = True):\n",
        "      if train:\n",
        "          self.data = X['train']\n",
        "          self.label1 = Y['train']\n",
        "          self.label2 = Z['train']\n",
        "      else:\n",
        "          self.data = X['test']\n",
        "          self.label1 = Y['test']\n",
        "          self.label2 = Z['test']\n",
        "        \n",
        "                \n",
        "    def __len__(self):\n",
        "        return len(self.label1)\n",
        "\n",
        "    def __preproc__(self, voxels):\n",
        "        \n",
        "        voxel_grid = voxels.get_voxels()\n",
        "        vox_g = np.zeros((32, 32, 32), dtype=np.int32)\n",
        "        for i in range (len(voxel_grid)):\n",
        "          voxel_index = voxel_grid[i].grid_index\n",
        "          vox_g[voxel_index[0],voxel_index[1],voxel_index[2]] = 1\n",
        "        \n",
        "        return vox_g.copy()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label1 = self.label1[idx]\n",
        "        label2 = self.label2[idx]\n",
        "        voxels = self.data[idx]\n",
        "        voxels = self.__preproc__(voxels)\n",
        "        voxels = np.expand_dims(voxels, axis=0)\n",
        "        voxels = torch.tensor(voxels).float()\n",
        "        return voxels, label1, label2"
      ],
      "metadata": {
        "id": "pfSGCV6k5YXr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import SGD, Adam\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from tqdm import tqdm\n",
        "\n",
        "class VoxNet_Trainer():\n",
        "  def __init__(self, hyperparameters):\n",
        "      #Hypreparameters\n",
        "      self.learning_rate = hyperparameters[\"learning_rate\"]\n",
        "      self.batch_size_train = hyperparameters[\"train_batch_size\"]\n",
        "      self.batch_size_test = hyperparameters[\"valid_batch_size\"]\n",
        "      self.data_size = hyperparameters[\"data_size\"]\n",
        "      self.sgd_momentum = hyperparameters[\"sgd_momentum\"]\n",
        "      self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "      self.epochs = hyperparameters[\"epochs\"]\n",
        "      self.name_model = hyperparameters[\"model\"]\n",
        "      self.best_acc = 0\n",
        "      \n",
        "      #Dataset\n",
        "      self.initDataset()\n",
        "      self.class_names = [\"bathtub\", \"bed\", \"chair\", \"desk\", \"dresser\", \"monitor\", \"night_stand\", \"sofa\", \"table\", \"toilet\"]\n",
        "      self.rotation_names = ['0', '45', '90', '135', '180', '225', '270', '315']\n",
        "      self.num_classes = len(self.class_names)\n",
        "      self.num_rotations = len(self.rotation_names)\n",
        "\n",
        "      #Model\n",
        "      self.lr_scheduler_step = hyperparameters[\"lr_scheduler_step\"]\n",
        "      self.lr_scheduler_gamma = hyperparameters[\"lr_scheduler_gamma\"]\n",
        "      self.initModel()\n",
        "  \n",
        "  def initDataset(self):\n",
        "      self.train_ds = VoxelDataset(train=True)\n",
        "      self.test_ds = VoxelDataset(train=False)\n",
        "      self.train_dataloader = DataLoader(dataset=self.train_ds, batch_size=self.batch_size_train, shuffle=True, drop_last=True)\n",
        "      self.test_dataloader = DataLoader(dataset=self.test_ds, batch_size=self.batch_size_test)\n",
        "\n",
        "  def initModel(self):\n",
        "      if self.name_model == \"VoxNet\":\n",
        "          self.model = VoxNet()\n",
        "          os.mkdir('/content/'+str(self.name_model))\n",
        "          print(\"model VoxNet was chosen\")\n",
        "      elif self.name_model == \"BatchNormVoxNet\":\n",
        "          self.model = BatchNormVoxNet()\n",
        "          os.mkdir('/content/'+str(self.name_model))\n",
        "          print(\"model BatchNormVoxNet was chosen\")\n",
        "      else:\n",
        "        self.model = DMPVoxNet()\n",
        "        os.mkdir('/content/'+str(self.name_model))\n",
        "        print('model DMPVoxNet was choosen')\n",
        "      self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "      self.model.to(self.device)\n",
        "      #self.opt = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "      self.opt = SGD(self.model.parameters(), lr=self.learning_rate, momentum=self.sgd_momentum)\n",
        "      self.loss_fn = nn.CrossEntropyLoss()\n",
        "      #self.loss_fn = nn.NLLLoss()\n",
        "      self.lr_scheduler = torch.optim.lr_scheduler.StepLR(self.opt, step_size=self.lr_scheduler_step, gamma=self.lr_scheduler_gamma)\n",
        "\n",
        "  def train(self):\n",
        "      self.pred_conf, self.y_conf = [], []                                                           \n",
        "      train_loss_history, valid_loss_history = [], []\n",
        "      train_acc_history1, valid_acc_history1 = [], []\n",
        "      train_acc_history2, valid_acc_history2 = [], []\n",
        "      train_accuracy1 = Accuracy(task='multiclass', num_classes=10)\n",
        "      valid_accuracy1 = Accuracy(task='multiclass', num_classes=10)\n",
        "      train_accuracy2 = Accuracy(task='multiclass', num_classes=8)\n",
        "      valid_accuracy2 = Accuracy(task='multiclass', num_classes=8)\n",
        "    \n",
        "\n",
        "      self.num_batch = len(self.train_ds) / self.batch_size_train\n",
        "      print(self.num_batch)\n",
        "\n",
        "      total_time = time.time()\n",
        "\n",
        "      for epoch in range(self.epochs):\n",
        "          t = time.time()\n",
        "\n",
        "          train_loss = []                                                         #track training loss\n",
        "          valid_loss = []\n",
        "\n",
        "          self.model.train()\n",
        "          iterator = tqdm(enumerate(self.train_dataloader, 0))\n",
        "          for i, data in iterator:\n",
        "              inputs, labels1, labels2 = data[0], data[1], data[2]\n",
        "              inputs = inputs.to(self.device)\n",
        "              labels1 = labels1.to(self.device)\n",
        "              labels2 = labels2.to(self.device)\n",
        "\n",
        "              self.opt.zero_grad()\n",
        "              pred1, pred2 = self.model(inputs)  # torch.Size([256, 10])\n",
        "              loss = 0.5*self.loss_fn(pred1, labels1) + 0.5*self.loss_fn(pred2, labels2)\n",
        "              train_loss.append(loss.cpu().data)\n",
        "              train_accuracy1.update(torch.argmax(pred1, 1).cpu(), labels1.cpu()) \n",
        "              train_accuracy2.update(torch.argmax(pred2, 1).cpu(), labels2.cpu()) \n",
        "            \n",
        "              loss.backward()\n",
        "              self.opt.step()\n",
        "              iterator.set_description(f\"Train loss: {loss.cpu().data}\")\n",
        "              \n",
        "              #pred_choice = pred.data.max(1)[1]\n",
        "              #correct = pred_choice.eq(labels.data).cpu().sum()\n",
        "          self.lr_scheduler.step()\n",
        "                      \n",
        "          with torch.no_grad():\n",
        "            self.model.eval()\n",
        "            pred_test1 = []       \n",
        "            pred_test2 = []  \n",
        "            for j, sample in tqdm(enumerate(self.test_dataloader, 0)):    \n",
        "                inputs_test, labels_test1, labels_test2 = sample[0], sample[1], sample[2]\n",
        "                inputs_test = inputs_test.to(self.device)\n",
        "                labels_test1 = labels_test1.to(self.device)\n",
        "                labels_test2 = labels_test2.to(self.device)\n",
        "                inputs_test = inputs_test.float()  \n",
        "\n",
        "                '''\n",
        "                pred_test1.append(self.model(inputs_test)[0])\n",
        "                pred_test2.append(self.model(inputs_test)[1])\n",
        "                pred_test = []\n",
        "                labels_test = []\n",
        "                for k in range(0, 25, 8):\n",
        "                    temp = pred_test1[j]\n",
        "                    tempo = temp[k:k+7,:]\n",
        "                    pred_test.append(np.einsum('ij->j', tempo))\n",
        "                    temp2 = labels_test1\n",
        "                    labels_test.append(temp2[k])\n",
        "\n",
        "                pred_test_t = torch.tensor(pred_test)\n",
        "                labels_test_t = torch.tensor(labels_test)\n",
        "                pred_test2_t = torch.tensor(pred_test2[j])\n",
        "                loss_test = self.loss_fn(pred_test_t, labels_test_t) \n",
        "                valid_loss.append(loss_test.cpu().data)\n",
        "                valid_accuracy1.update(torch.argmax(pred_test_t, 1).cpu(), labels_test_t.cpu())\n",
        "                valid_accuracy2.update(torch.argmax(pred_test2_t, 1).cpu(), labels_test2.cpu())\n",
        "                pred_choice_test = pred_test_t.data.max(1)[1]\n",
        "\n",
        "                correct_test = pred_choice_test.eq(labels_test_t.data).cpu().sum()\n",
        "                self.pred_conf.append(torch.argmax(pred_test_t, 1))\n",
        "                self.y_conf.append(labels_test_t)\n",
        "                '''\n",
        "                \n",
        "                pred_test1, pred_test2 = self.model(inputs_test)  # torch.Size([256, 10])\n",
        "                loss_test = 0.5*self.loss_fn(pred_test1, labels_test1) + 0.5*self.loss_fn(pred_test2, labels_test2)\n",
        "                valid_loss.append(loss_test.cpu().data)\n",
        "                valid_accuracy1.update(torch.argmax(pred_test1, 1).cpu(), labels_test1.cpu()) \n",
        "                valid_accuracy2.update(torch.argmax(pred_test2, 1).cpu(), labels_test2.cpu()) \n",
        "                \n",
        "                #correct_test = pred_choice_test.eq(labels_test.data).cpu().sum()\n",
        "                self.pred_conf.append(torch.argmax(pred_test1, 1))\n",
        "                self.y_conf.append(labels_test1)\n",
        "      \n",
        "\n",
        "          # total accuracy over all batches\n",
        "          total_train_accuracy1 = train_accuracy1.compute()\n",
        "          total_train_accuracy2 = train_accuracy2.compute()\n",
        "          total_valid_accuracy1 = valid_accuracy1.compute()\n",
        "          total_valid_accuracy2 = valid_accuracy2.compute()\n",
        "          train_accuracy1.reset()\n",
        "          valid_accuracy1.reset()\n",
        "          train_accuracy2.reset()\n",
        "          valid_accuracy2.reset()\n",
        "            \n",
        "          #track loss and acc for plotting\n",
        "          train_loss_history.append(torch.mean(torch.tensor(train_loss)))\n",
        "          valid_loss_history.append(torch.mean(torch.tensor(valid_loss)))\n",
        "          train_acc_history1.append(total_train_accuracy1)\n",
        "          train_acc_history2.append(total_train_accuracy2)\n",
        "          valid_acc_history1.append(total_valid_accuracy1)\n",
        "          valid_acc_history2.append(total_valid_accuracy2)\n",
        "          \n",
        "            \n",
        "          elapsed_time_epoch = time.time() - t   \n",
        "            \n",
        "          tmp0 = \"epoch:{:3d} /{:3d}\".format(epoch+1, self.epochs)\n",
        "          tmp1 = \"time: {:.2f} seconds\".format(elapsed_time_epoch)\n",
        "          tmp2 = \"train-loss: {:4.2f}, train-acc-object: {:.2%}, train-acc-pose: {:.2%}\".format(train_loss_history[epoch], train_acc_history1[epoch].item(), train_acc_history2[epoch].item())\n",
        "          tmp3 = \"valid-loss: {:4.2f}, valid-acc-object: {:.2%}, train-acc-pose: {:.2%}\\n\".format(valid_loss_history[epoch], valid_acc_history1[epoch].item(), valid_acc_history2[epoch].item())\n",
        "          print(tmp0, tmp1, tmp2, tmp3, sep=\"\\n\")\n",
        "\n",
        "\n",
        "          ##save best model \n",
        "          if total_valid_accuracy1.numpy()>self.best_acc:\n",
        "              self.best_acc = total_valid_accuracy1.numpy()\n",
        "              torch.save({'epoch': epoch+1,\n",
        "                          'model_state_dict': self.model.state_dict(),\n",
        "                          'optimizer_state_dict': self.opt.state_dict(),\n",
        "                          'loss': valid_loss_history[-1], \n",
        "                          'accuracy': total_valid_accuracy1},\n",
        "\t                        '/content/'+str(self.name_model)+'/best_model.pth')\n",
        "\n",
        "          \n",
        "          #save history\n",
        "          self.history = {\"train_loss\": torch.tensor(train_loss_history), \"train_acc1\": torch.tensor(train_acc_history1), \"train_acc2\": torch.tensor(train_acc_history2), \n",
        "                          \"valid_loss\": torch.tensor(valid_loss_history), \"valid_acc1\": torch.tensor(valid_acc_history1), \"valid_acc2\": torch.tensor(valid_acc_history2)}\n",
        "           \n",
        "  def getHistory(self):\n",
        "      return self.history\n",
        "\n",
        "  def generateConfusionMatrix(self):\n",
        "      ##load the model\n",
        "      checkpoint = torch.load('/content/'+str(self.name_model)+'/best_model.pth')\n",
        "      self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "      self.opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "      loss = checkpoint['loss']\n",
        "      epoch = checkpoint['epoch']\n",
        "      acc = checkpoint['accuracy']\n",
        "      print('best model was trained at epoch: '+str(epoch))\n",
        "      print('with a validation loss of: '+str(loss.numpy())+' and a validation accuracy of: '+str(acc.numpy()*100))\n",
        "  \n",
        "      ##compute confusion matrix\n",
        "      self.model.eval()\n",
        "      a = torch.cat(self.pred_conf).cpu()\n",
        "      b = torch.cat(self.y_conf).cpu()\n",
        "      confmat = ConfusionMatrix(task='multiclass', num_classes=10, normalize=\"true\")\n",
        "      self.conf_matrix = confmat(a, b)\n",
        "      self.conf_matrix = torch.round(self.conf_matrix, decimals=2)\n",
        "\n",
        "      fig=plt.figure(figsize = (12,7))\n",
        "      sns.heatmap(self.conf_matrix, annot=True, fmt='g', linewidths=.4, cbar=False)\n",
        "      tick_marks = np.arange(len(self.class_names))\n",
        "      plt.xticks(tick_marks, self.class_names, rotation=45)\n",
        "      plt.yticks(tick_marks, self.class_names, rotation=0)\n",
        "      plt.title(\"Confusion Matrix\")     \n",
        "\n",
        "  def getPerClassAccuracy(self):\n",
        "      per_class_accuracy = 100 * torch.diag(self.conf_matrix) / torch.sum(self.conf_matrix, 1)\n",
        "      tmp = {}\n",
        "      for i, x in enumerate(self.class_names):\n",
        "        tmp[x] = per_class_accuracy[i].item()\n",
        "      print(tmp)\n",
        "    \n",
        "  def showResults(self):\n",
        "      eps = range(0, len(self.history[\"train_loss\"].cpu()))\n",
        "        \n",
        "      sns.set_theme()\n",
        "      fig, ax = plt.subplots(1, 2, figsize=(14, 4))\n",
        "      fig.suptitle('Results')\n",
        "        \n",
        "      ax[0].plot(eps, smooth(self.history[\"train_loss\"].cpu()), 'g', label='Training Loss')\n",
        "      ax[0].plot(eps, smooth(self.history[\"valid_loss\"].cpu()), 'b', label='Valid Loss')\n",
        "      ax[0].set_title('Loss History')\n",
        "      ax[0].set(xlabel='Epochs', ylabel='Loss')\n",
        "      ax[0].legend()\n",
        "        \n",
        "      ax[1].plot(eps, smooth(self.history[\"train_acc1\"].cpu()), 'g', label='Training Accuracy object')\n",
        "      ax[1].plot(eps, smooth(self.history[\"train_acc2\"].cpu()), 'k', label='Training Accuracy pose')\n",
        "      ax[1].plot(eps, smooth(self.history[\"valid_acc1\"].cpu()), 'b', label='Valid Accuracy object')\n",
        "      ax[1].plot(eps, smooth(self.history[\"valid_acc2\"].cpu()), 'r', label='Valid Accuracy pose')\n",
        "      ax[1].set_title('Accuracy History')\n",
        "      ax[1].set(xlabel='Epochs', ylabel='Accuracy')\n",
        "      ax[1].legend()\n",
        "\n",
        "  def draw_voxels(self):\n",
        "      mesh = next(iter(self.train_dataloader))\n",
        "      mesh = mesh[0][0][0]\n",
        "        \n",
        "      ax = plt.figure(figsize=(10,10)).add_subplot(projection='3d')\n",
        "      ax.voxels(mesh, edgecolor='k')\n",
        "      plt.show()\n",
        "        \n",
        "  def test_on_missing_data(self, missing_rate=0.5):\n",
        "      test_accuracy = Accuracy(task='multiclass', num_classes=10)\n",
        "\n",
        "      ##load the model\n",
        "      checkpoint = torch.load('/content/'+str(self.name_model)+'/best_model.pth')\n",
        "      self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "      self.opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "      loss = checkpoint['loss']\n",
        "      epoch = checkpoint['epoch']\n",
        "      acc = checkpoint['accuracy']\n",
        "  \n",
        "      self.model.eval()\n",
        "      for x, y, z in self.test_dataloader:\n",
        "          x, y, z = x.to(self.device), y.to(self.device), z.to(self.device)\n",
        "            \n",
        "          idc = np.random.choice(32**3, size=(int(32**3*missing_rate)), replace=False)\n",
        "          idc_x = idc%32\n",
        "          idc_y = np.floor_divide(idc, 32)%32\n",
        "          idc_z = np.floor_divide(idc, 32*32)%32\n",
        "          x[:, :, idc_x, idc_y, idc_z] = 0\n",
        "            \n",
        "          pred = self.model(x)[0]\n",
        "          test_accuracy.update(torch.argmax(pred, 1).cpu(), y.cpu())\n",
        "            \n",
        "      return test_accuracy.compute()\n",
        "    \n",
        "  def missing_data_test(self):\n",
        "      acc = []\n",
        "      delta = 200\n",
        "      eps = np.linspace(0,0.99,delta)\n",
        "\n",
        "      ##load the model\n",
        "      checkpoint = torch.load('/content/'+str(self.name_model)+'/best_model.pth')\n",
        "      self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "      self.opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "      loss = checkpoint['loss']\n",
        "      epoch = checkpoint['epoch']\n",
        "      accu = checkpoint['accuracy']\n",
        "      print('best model was trained at epoch: '+str(epoch))\n",
        "      print('with a validation loss of: '+str(loss.numpy())+' and a validation accuracy of: '+str(accu.numpy()*100))\n",
        "\n",
        "      for x in eps:\n",
        "          tmp = self.test_on_missing_data(x)\n",
        "          acc.append(tmp)\n",
        "            \n",
        "            \n",
        "      sns.set_theme()\n",
        "      plt.figure(figsize=(8, 4))\n",
        "      plt.plot(eps, smooth(acc))\n",
        "      plt.title(\"Missing Data Test\", size=20, y=1.05)\n",
        "      plt.xlabel(\"missing point ratio\", size=15)\n",
        "      plt.ylabel(\"accuracy\", size=15)\n",
        "      plt.show()"
      ],
      "metadata": {
        "id": "hX_KJavxavhZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VoxNet"
      ],
      "metadata": {
        "id": "eu7HegQogDfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "class VoxNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VoxNet, self).__init__()\n",
        "        n_classes = 10\n",
        "        n_rotations = 8\n",
        "        input_shape = (32,32,32)\n",
        "        self.feat = torch.nn.Sequential(OrderedDict([\n",
        "            ('conv3d_1', torch.nn.Conv3d(in_channels=1, out_channels=32, kernel_size=5, stride=2)),\n",
        "            ('relu1', torch.nn.ReLU()),\n",
        "            ('drop1', torch.nn.Dropout(p=0.2)),\n",
        "            ('conv3d_2', torch.nn.Conv3d(in_channels=32, out_channels=64, kernel_size=3, stride=1)),\n",
        "            ('relu2', torch.nn.ReLU()),\n",
        "            ('drop2', torch.nn.Dropout(p=0.3)),\n",
        "            ('pool1', torch.nn.MaxPool3d(kernel_size=2, stride=2))\n",
        "        ]))\n",
        "        \n",
        "        x = self.feat(torch.autograd.Variable(torch.rand((1, 1) + input_shape)))\n",
        "        dim_feat = 1\n",
        "        for n in x.size()[1:]:\n",
        "            dim_feat *= n\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(OrderedDict([\n",
        "            ('fc1', torch.nn.Linear(dim_feat, 128)),\n",
        "            ('relu1', torch.nn.ReLU()),\n",
        "            ('drop3', torch.nn.Dropout(p=0.4)),\n",
        "            ('fc2', torch.nn.Linear(128, n_classes))\n",
        "        ]))\n",
        "\n",
        "        self.mlp2 = torch.nn.Sequential(OrderedDict([\n",
        "            ('fc1', torch.nn.Linear(dim_feat, 128)),\n",
        "            ('relu1', torch.nn.ReLU()),\n",
        "            ('drop3', torch.nn.Dropout(p=0.4)),\n",
        "            ('fc2', torch.nn.Linear(128, n_rotations))\n",
        "        ]))\n",
        "\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feat(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x1 = self.mlp(x)\n",
        "        x2 = self.mlp2(x)\n",
        "        #return x\n",
        "        return self.logsoftmax(x1), self.logsoftmax(x2)"
      ],
      "metadata": {
        "id": "BxJn-rxg5thp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VoxNet** training"
      ],
      "metadata": {
        "id": "auLDuguFtGq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_hyperparameters = {\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"sgd_momentum\": 0.9,\n",
        "    \"data_size\": 32,\n",
        "    \"epochs\": 50,\n",
        "    \"lr_scheduler_step\": 8,\n",
        "    \"lr_scheduler_gamma\": 0.3,\n",
        "    \"train_batch_size\": 32,\n",
        "    \"valid_batch_size\": 32,\n",
        "    \"model\" : 'VoxNet'\n",
        "}    \n",
        "\n",
        "trainer1 = VoxNet_Trainer(training_hyperparameters)\n",
        "trainer1.train()"
      ],
      "metadata": {
        "id": "HBhOIt8Emq1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def smooth(x, w=0):\n",
        "    last = x[0]\n",
        "    smoothed = []\n",
        "    for point in x:\n",
        "      smoothed_val = w * last + (1 - w) * point\n",
        "      smoothed.append(smoothed_val)\n",
        "      ast = smoothed_val\n",
        "          \n",
        "    return smoothed\n",
        "\n",
        "history1 = trainer1.getHistory()\n",
        "trainer1.showResults()"
      ],
      "metadata": {
        "id": "N7DHiwXimwKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer1.generateConfusionMatrix()"
      ],
      "metadata": {
        "id": "yr5CE5Zjw9Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer1.missing_data_test()"
      ],
      "metadata": {
        "id": "s30abd-s2seu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BatcNormVoxNet"
      ],
      "metadata": {
        "id": "cgdQgwjggYGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "class BatchNormVoxNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BatchNormVoxNet, self).__init__()\n",
        "        n_classes = 10\n",
        "        n_rotations = 8\n",
        "        input_shape = (32,32,32)\n",
        "        self.feat = torch.nn.Sequential(OrderedDict([\n",
        "            ('conv3d_1', torch.nn.Conv3d(in_channels=1, out_channels=32, kernel_size=3, stride=2)),\n",
        "            ('relu1', torch.nn.ReLU()),\n",
        "            ('batch1', torch.nn.BatchNorm3d(32)),\n",
        "            ('drop1', torch.nn.Dropout(p=0.2)),\n",
        "            ('conv3d_2', torch.nn.Conv3d(in_channels=32, out_channels=64, kernel_size=3, stride=1)),\n",
        "            ('batch2', torch.nn.BatchNorm3d(64)),\n",
        "            ('relu2', torch.nn.ReLU()),\n",
        "            ('drop2', torch.nn.Dropout(p=0.3)),\n",
        "            ('conv3d_3', torch.nn.Conv3d(in_channels=64, out_channels=128, kernel_size=3, stride=1)),\n",
        "            ('batch3', torch.nn.BatchNorm3d(128)),\n",
        "            ('relu3', torch.nn.ReLU()),\n",
        "            ('drop3', torch.nn.Dropout(p=0.3)),\n",
        "            ('conv3d_4', torch.nn.Conv3d(in_channels=128, out_channels=256, kernel_size=3, stride=1)),\n",
        "            ('relu4', torch.nn.ReLU()),\n",
        "            ('drop4', torch.nn.Dropout(p=0.4)),\n",
        "            ('pool1', torch.nn.MaxPool3d(kernel_size=2, stride=2))\n",
        "        ]))\n",
        "        \n",
        "        x = self.feat(torch.autograd.Variable(torch.rand((1, 1) + input_shape)))\n",
        "        dim_feat = 1\n",
        "        for n in x.size()[1:]:\n",
        "            dim_feat *= n\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(OrderedDict([\n",
        "            ('fc1', torch.nn.Linear(dim_feat, 128)),\n",
        "            ('relu1', torch.nn.ReLU()),\n",
        "            ('drop3', torch.nn.Dropout(p=0.4)),\n",
        "            ('fc2', torch.nn.Linear(128, n_classes))\n",
        "        ]))\n",
        "\n",
        "        self.mlp2 = torch.nn.Sequential(OrderedDict([\n",
        "            ('fc1', torch.nn.Linear(dim_feat, 128)),\n",
        "            ('relu1', torch.nn.ReLU()),\n",
        "            ('drop3', torch.nn.Dropout(p=0.4)),\n",
        "            ('fc2', torch.nn.Linear(128, n_rotations))\n",
        "        ]))\n",
        "\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feat(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x1 = self.mlp(x)\n",
        "        x2 = self.mlp2(x)\n",
        "        return x1, x2\n",
        "        #return self.logsoftmax(x1), self.logsoftmax(x2)"
      ],
      "metadata": {
        "id": "1RYhudhkrK6P"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BatchNormVoxNet** Training "
      ],
      "metadata": {
        "id": "QvYd-EqMtBtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_hyperparameters = {\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"sgd_momentum\": 0.9,\n",
        "    \"data_size\": 32,\n",
        "    \"epochs\": 50,\n",
        "    \"lr_scheduler_step\": 10,\n",
        "    \"lr_scheduler_gamma\": 0.3,\n",
        "    \"train_batch_size\": 64,\n",
        "    \"valid_batch_size\": 64,\n",
        "    \"model\" : 'BatchNormVoxNet'\n",
        "}    \n",
        "\n",
        "trainer2 = VoxNet_Trainer(training_hyperparameters)\n",
        "trainer2.train()"
      ],
      "metadata": {
        "id": "s13Dp_TUIeF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def smooth(x, w=0):\n",
        "    last = x[0]\n",
        "    smoothed = []\n",
        "    for point in x:\n",
        "      smoothed_val = w * last + (1 - w) * point\n",
        "      smoothed.append(smoothed_val)\n",
        "      ast = smoothed_val\n",
        "          \n",
        "    return smoothed\n",
        "\n",
        "history2 = trainer2.getHistory()\n",
        "trainer2.showResults()"
      ],
      "metadata": {
        "id": "iQBg4PkSyFYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer2.generateConfusionMatrix()"
      ],
      "metadata": {
        "id": "C_0cmlsu3sg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer2.missing_data_test()"
      ],
      "metadata": {
        "id": "SaU97bMwNNmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DMPVoxNet (double-max-pooling VoxNet)"
      ],
      "metadata": {
        "id": "_nmRSyb7g_3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "class DMPVoxNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DMPVoxNet, self).__init__()\n",
        "        n_classes = 10\n",
        "        n_rotations = 8\n",
        "        input_shape = (32,32,32)\n",
        "        self.feat = torch.nn.Sequential(OrderedDict([\n",
        "            ('conv3d_1', torch.nn.Conv3d(in_channels=1, out_channels=32, kernel_size=3, stride=1)),\n",
        "            ('relu1', torch.nn.ReLU()),\n",
        "            ('pool1', torch.nn.MaxPool3d(2)),\n",
        "            ('drop1', torch.nn.Dropout(p=0.5)),\n",
        "            ('conv3d_2', torch.nn.Conv3d(in_channels=32, out_channels=64, kernel_size=3)),\n",
        "            ('relu2', torch.nn.ReLU()),\n",
        "            ('pool2', torch.nn.MaxPool3d(2)),\n",
        "            ('drop2', torch.nn.Dropout(p=0.5))\n",
        "        ]))\n",
        "        \n",
        "        x = self.feat(torch.autograd.Variable(torch.rand((1, 1) + input_shape)))\n",
        "        dim_feat = 1\n",
        "        for n in x.size()[1:]:\n",
        "            dim_feat *= n\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(OrderedDict([\n",
        "            ('fc1', torch.nn.Linear(dim_feat, 128)),\n",
        "            ('relu1', torch.nn.ReLU()),\n",
        "            ('drop3', torch.nn.Dropout(p=0.4)),\n",
        "            ('fc2', torch.nn.Linear(128, n_classes))\n",
        "        ]))\n",
        "\n",
        "        self.mlp2 = torch.nn.Sequential(OrderedDict([\n",
        "            ('fc1', torch.nn.Linear(dim_feat, 128)),\n",
        "            ('relu1', torch.nn.ReLU()),\n",
        "            ('drop3', torch.nn.Dropout(p=0.4)),\n",
        "            ('fc2', torch.nn.Linear(128, n_rotations))\n",
        "        ]))\n",
        "\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feat(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x1 = self.mlp(x)\n",
        "        x2 = self.mlp2(x)\n",
        "        return x1, x2\n",
        "        #return self.logsoftmax(x1), self.logsoftmax(x2)"
      ],
      "metadata": {
        "id": "iUmops89RNwb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DMPVoxNet** training"
      ],
      "metadata": {
        "id": "3Dsd4G6CrcYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_hyperparameters = {\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"sgd_momentum\": 0.9,\n",
        "    \"data_size\": 32,\n",
        "    \"epochs\": 50,\n",
        "    \"lr_scheduler_step\": 10,\n",
        "    \"lr_scheduler_gamma\": 0.5,\n",
        "    \"train_batch_size\": 32,\n",
        "    \"valid_batch_size\": 32,\n",
        "    \"model\" : 'DMPVoxNet'\n",
        "}    \n",
        "\n",
        "trainer3 = VoxNet_Trainer(training_hyperparameters)\n",
        "trainer3.train()"
      ],
      "metadata": {
        "id": "SGl_plCpmEmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def smooth(x, w=0):\n",
        "    last = x[0]\n",
        "    smoothed = []\n",
        "    for point in x:\n",
        "      smoothed_val = w * last + (1 - w) * point\n",
        "      smoothed.append(smoothed_val)\n",
        "      ast = smoothed_val\n",
        "          \n",
        "    return smoothed\n",
        "\n",
        "history3 = trainer3.getHistory()\n",
        "trainer3.showResults()"
      ],
      "metadata": {
        "id": "3XJmF6X3UKYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer3.generateConfusionMatrix()"
      ],
      "metadata": {
        "id": "VXQPjIZWUZlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer3.missing_data_test()"
      ],
      "metadata": {
        "id": "ektxV3YdUhzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VoxNet model comparison"
      ],
      "metadata": {
        "id": "WLvqsX2ZhV6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def smooth(x, w=0):\n",
        "    last = x[0]\n",
        "    smoothed = []\n",
        "    for point in x:\n",
        "      smoothed_val = w * last + (1 - w) * point\n",
        "      smoothed.append(smoothed_val)\n",
        "      ast = smoothed_val\n",
        "          \n",
        "    return smoothed\n",
        "\n",
        "eps = range(0, len(history1[\"train_loss\"].cpu()))\n",
        "        \n",
        "sns.set_theme()\n",
        "fig, ax = plt.subplots(2, 2, figsize=(20, 10))\n",
        "fig.suptitle('Results')\n",
        "        \n",
        "ax[0,0].plot(eps, smooth(history1[\"train_loss\"].cpu()), 'g', label='Training Loss VoxNet')\n",
        "ax[0,0].plot(eps, smooth(history2[\"train_loss\"].cpu()), 'b', label='Training Loss BVoxNet')\n",
        "ax[0,0].plot(eps, smooth(history3[\"train_loss\"].cpu()), 'r', label='Training Loss DMPVoxNet')\n",
        "ax[0,0].set_title('Training Loss History')\n",
        "ax[0,0].set(xlabel='Epochs', ylabel='Loss')\n",
        "ax[0,0].legend()\n",
        "        \n",
        "ax[0,1].plot(eps, smooth(history1[\"valid_loss\"].cpu()), 'g', label='Valid Loss VoxNet')\n",
        "ax[0,1].plot(eps, smooth(history2[\"valid_loss\"].cpu()), 'b', label='Valid Loss BVoxNet')\n",
        "ax[0,1].plot(eps, smooth(history3[\"valid_loss\"].cpu()), 'r', label='Valid Loss DMPVoxNet')\n",
        "ax[0,1].set_title('Valid Loss History')\n",
        "ax[0,1].set(xlabel='Epochs', ylabel='Loss')\n",
        "ax[0,1].legend()\n",
        "\n",
        "ax[1,0].plot(eps, smooth(history1[\"train_acc1\"].cpu()), 'g', label='Training Accuracy VoxNet')\n",
        "ax[1,0].plot(eps, smooth(history2[\"train_acc1\"].cpu()), 'b', label='Training Accuracy BVoxNet')\n",
        "ax[1,0].plot(eps, smooth(history3[\"train_acc1\"].cpu()), 'r', label='Training Accuracy DMPVoxNet')\n",
        "ax[1,0].set_title('Training Accuracy History')\n",
        "ax[1,0].set(xlabel='Epochs', ylabel='Accuracy')\n",
        "ax[1,0].legend()\n",
        "\n",
        "ax[1,1].plot(eps, smooth(history1[\"valid_acc1\"].cpu()), 'g', label='Valid Accuracy VoxNet')\n",
        "ax[1,1].plot(eps, smooth(history2[\"valid_acc1\"].cpu()), 'b', label='Valid Accuracy BVoxNet')\n",
        "ax[1,1].plot(eps, smooth(history3[\"valid_acc1\"].cpu()), 'r', label='Valid Accuracy DMPVoxNet')\n",
        "ax[1,1].set_title('Valid Accuracy History')\n",
        "ax[1,1].set(xlabel='Epochs', ylabel='Accuracy')\n",
        "ax[1,1].legend()"
      ],
      "metadata": {
        "id": "01eRVcGrA8c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PointNet"
      ],
      "metadata": {
        "id": "lXW9DHjvDXRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import math\n",
        "\n",
        "!pip install path.py;\n",
        "from path import Path\n",
        "\n",
        "path = Path(\"ModelNet10\")\n",
        "\n",
        "folders = [dir for dir in sorted(os.listdir(path)) if os.path.isdir(path/dir)]\n",
        "classes = {folder: i for i, folder in enumerate(folders)};\n",
        "\n",
        "def read_off(file):\n",
        "    if 'OFF' != file.readline().strip():\n",
        "        raise('Not a valid OFF header')\n",
        "    n_verts, n_faces, __ = tuple([int(s) for s in file.readline().strip().split(' ')])\n",
        "    verts = [[float(s) for s in file.readline().strip().split(' ')] for i_vert in range(n_verts)]\n",
        "    faces = [[int(s) for s in file.readline().strip().split(' ')][1:] for i_face in range(n_faces)]\n",
        "    return verts, faces"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHQA_PqX__lv",
        "outputId": "0f4c5b29-baad-40b7-ee62-b220637f161c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting path.py\n",
            "  Downloading path.py-12.5.0-py3-none-any.whl (2.3 kB)\n",
            "Collecting path\n",
            "  Downloading path-16.6.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: path, path.py\n",
            "Successfully installed path-16.6.0 path.py-12.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PointSampler(object):\n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, int)\n",
        "        self.output_size = output_size\n",
        "    \n",
        "    def triangle_area(self, pt1, pt2, pt3):\n",
        "        side_a = np.linalg.norm(pt1 - pt2)\n",
        "        side_b = np.linalg.norm(pt2 - pt3)\n",
        "        side_c = np.linalg.norm(pt3 - pt1)\n",
        "        s = 0.5 * ( side_a + side_b + side_c)\n",
        "        return max(s * (s - side_a) * (s - side_b) * (s - side_c), 0)**0.5\n",
        "\n",
        "    def sample_point(self, pt1, pt2, pt3):\n",
        "        # barycentric coordinates on a triangle\n",
        "        # https://mathworld.wolfram.com/BarycentricCoordinates.html\n",
        "        s, t = sorted([random.random(), random.random()])\n",
        "        f = lambda i: s * pt1[i] + (t-s)*pt2[i] + (1-t)*pt3[i]\n",
        "        return (f(0), f(1), f(2))\n",
        "        \n",
        "    \n",
        "    def __call__(self, mesh):\n",
        "        verts, faces = mesh\n",
        "        verts = np.array(verts)\n",
        "        areas = np.zeros((len(faces)))\n",
        "\n",
        "        for i in range(len(areas)):\n",
        "            areas[i] = (self.triangle_area(verts[faces[i][0]], verts[faces[i][1]], verts[faces[i][2]]))\n",
        "            \n",
        "        sampled_faces = (random.choices(faces, weights=areas, cum_weights=None, k=self.output_size))\n",
        "        \n",
        "        sampled_points = np.zeros((self.output_size, 3))\n",
        "\n",
        "        for i in range(len(sampled_faces)):\n",
        "            sampled_points[i] = (self.sample_point(verts[sampled_faces[i][0]], verts[sampled_faces[i][1]], verts[sampled_faces[i][2]]))\n",
        "        \n",
        "        return sampled_points\n",
        "\n",
        "\n",
        "class Normalize(object):\n",
        "    def __call__(self, pointcloud):\n",
        "        assert len(pointcloud.shape)==2\n",
        "        \n",
        "        norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0) \n",
        "        norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n",
        "\n",
        "        return  norm_pointcloud\n",
        "\n",
        "class RandRotation_z(object):\n",
        "    def __call__(self, pointcloud):\n",
        "        assert len(pointcloud.shape)==2\n",
        "\n",
        "        theta = random.random() * 2. * math.pi\n",
        "        rot_matrix = np.array([[ math.cos(theta), -math.sin(theta),    0],\n",
        "                               [ math.sin(theta),  math.cos(theta),    0],\n",
        "                               [0,                             0,      1]])\n",
        "        \n",
        "        rot_pointcloud = rot_matrix.dot(pointcloud.T).T\n",
        "        return  rot_pointcloud\n",
        "    \n",
        "class RandomNoise(object):\n",
        "    def __call__(self, pointcloud):\n",
        "        assert len(pointcloud.shape)==2\n",
        "\n",
        "        noise = np.random.normal(0, 0.02, (pointcloud.shape))\n",
        "    \n",
        "        noisy_pointcloud = pointcloud + noise\n",
        "        return  noisy_pointcloud\n",
        "\n",
        "class ToTensor(object):\n",
        "    def __call__(self, pointcloud):\n",
        "        assert len(pointcloud.shape)==2\n",
        "\n",
        "        return torch.from_numpy(pointcloud)"
      ],
      "metadata": {
        "id": "9sth9zUqAXB2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def default_transforms():\n",
        "    return transforms.Compose([PointSampler(1024),\n",
        "                                Normalize(),\n",
        "                                ToTensor()\n",
        "                              ])"
      ],
      "metadata": {
        "id": "tn-WdIPaAjcr"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "class PointCloudData(Dataset):\n",
        "    def __init__(self, root_dir, valid=False, folder=\"train\", transform=default_transforms()):\n",
        "        self.root_dir = root_dir\n",
        "        folders = [dir for dir in sorted(os.listdir(root_dir)) if os.path.isdir(root_dir/dir)]\n",
        "        self.classes = {folder: i for i, folder in enumerate(folders)}\n",
        "        self.transforms = transform if not valid else default_transforms()\n",
        "        self.valid = valid\n",
        "        self.files = []\n",
        "        for category in self.classes.keys():\n",
        "            new_dir = root_dir/Path(category)/folder\n",
        "            for file in os.listdir(new_dir):\n",
        "                if file.endswith('.off'):\n",
        "                    sample = {}\n",
        "                    sample['pcd_path'] = new_dir/file\n",
        "                    sample['category'] = category\n",
        "                    self.files.append(sample)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __preproc__(self, file):\n",
        "        verts, faces = read_off(file)\n",
        "        if self.transforms:\n",
        "            pointcloud = self.transforms((verts, faces))\n",
        "        return pointcloud\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pcd_path = self.files[idx]['pcd_path']\n",
        "        category = self.files[idx]['category']\n",
        "        with open(pcd_path, 'r') as f:\n",
        "            pointcloud = self.__preproc__(f)\n",
        "        return {'pointcloud': pointcloud, 'category': self.classes[category]}"
      ],
      "metadata": {
        "id": "W1FJfREUA4wD"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "                    PointSampler(1024),\n",
        "                    Normalize(),\n",
        "                    RandRotation_z(),\n",
        "                    RandomNoise(),\n",
        "                    ToTensor()\n",
        "                    ])"
      ],
      "metadata": {
        "id": "rQXlaI5oBAkz"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Tnet(nn.Module):\n",
        "   def __init__(self, k=3):\n",
        "      super().__init__()\n",
        "      self.k=k\n",
        "      self.conv1 = nn.Conv1d(k,64,1)\n",
        "      self.conv2 = nn.Conv1d(64,128,1)\n",
        "      self.conv3 = nn.Conv1d(128,1024,1)\n",
        "      self.fc1 = nn.Linear(1024,512)\n",
        "      self.fc2 = nn.Linear(512,256)\n",
        "      self.fc3 = nn.Linear(256,k*k)\n",
        "\n",
        "      self.bn1 = nn.BatchNorm1d(64)\n",
        "      self.bn2 = nn.BatchNorm1d(128)\n",
        "      self.bn3 = nn.BatchNorm1d(1024)\n",
        "      self.bn4 = nn.BatchNorm1d(512)\n",
        "      self.bn5 = nn.BatchNorm1d(256)\n",
        "       \n",
        "\n",
        "   def forward(self, input):\n",
        "      # input.shape == (bs,n,3)\n",
        "      bs = input.size(0)\n",
        "      xb = F.relu(self.bn1(self.conv1(input)))\n",
        "      xb = F.relu(self.bn2(self.conv2(xb)))\n",
        "      xb = F.relu(self.bn3(self.conv3(xb)))\n",
        "      pool = nn.MaxPool1d(xb.size(-1))(xb)\n",
        "      flat = nn.Flatten(1)(pool)\n",
        "      xb = F.relu(self.bn4(self.fc1(flat)))\n",
        "      xb = F.relu(self.bn5(self.fc2(xb)))\n",
        "      \n",
        "      #initialize as identity\n",
        "      init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
        "      if xb.is_cuda:\n",
        "        init=init.cuda()\n",
        "      matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n",
        "      return matrix\n",
        "\n",
        "\n",
        "class Transform(nn.Module):\n",
        "   def __init__(self):\n",
        "        super().__init__()\n",
        "        self.input_transform = Tnet(k=3)\n",
        "        self.feature_transform = Tnet(k=64)\n",
        "        self.conv1 = nn.Conv1d(3,64,1)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(64,128,1)\n",
        "        self.conv3 = nn.Conv1d(128,1024,1)\n",
        "       \n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(1024)\n",
        "       \n",
        "   def forward(self, input):\n",
        "        matrix3x3 = self.input_transform(input)\n",
        "        # batch matrix multiplication\n",
        "        xb = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n",
        "\n",
        "        xb = F.relu(self.bn1(self.conv1(xb)))\n",
        "\n",
        "        matrix64x64 = self.feature_transform(xb)\n",
        "        xb = torch.bmm(torch.transpose(xb,1,2), matrix64x64).transpose(1,2)\n",
        "\n",
        "        xb = F.relu(self.bn2(self.conv2(xb)))\n",
        "        xb = self.bn3(self.conv3(xb))\n",
        "        xb = nn.MaxPool1d(xb.size(-1))(xb)\n",
        "        output = nn.Flatten(1)(xb)\n",
        "        return output, matrix3x3, matrix64x64\n",
        "\n",
        "class PointNet(nn.Module):\n",
        "    def __init__(self, classes = 10):\n",
        "        super().__init__()\n",
        "        self.transform = Transform()\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, classes)\n",
        "        \n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        xb, matrix3x3, matrix64x64 = self.transform(input)\n",
        "        xb = F.relu(self.bn1(self.fc1(xb)))\n",
        "        xb = F.relu(self.bn2(self.dropout(self.fc2(xb))))\n",
        "        output = self.fc3(xb)\n",
        "        return self.logsoftmax(output), matrix3x3, matrix64x64"
      ],
      "metadata": {
        "id": "Yqn1xNHOBLIE"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pointnetloss(outputs, labels, m3x3, m64x64, alpha = 0.0001):\n",
        "    criterion = torch.nn.NLLLoss()\n",
        "    bs=outputs.size(0)\n",
        "    id3x3 = torch.eye(3, requires_grad=True).repeat(bs,1,1)\n",
        "    id64x64 = torch.eye(64, requires_grad=True).repeat(bs,1,1)\n",
        "    if outputs.is_cuda:\n",
        "        id3x3=id3x3.cuda()\n",
        "        id64x64=id64x64.cuda()\n",
        "    diff3x3 = id3x3-torch.bmm(m3x3,m3x3.transpose(1,2))\n",
        "    diff64x64 = id64x64-torch.bmm(m64x64,m64x64.transpose(1,2))\n",
        "    return criterion(outputs, labels) + alpha * (torch.norm(diff3x3)+torch.norm(diff64x64)) / float(bs)"
      ],
      "metadata": {
        "id": "LE_Wi6HiBQrK"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import SGD, Adam\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from tqdm import tqdm\n",
        "\n",
        "class PointNet_Trainer():\n",
        "  def __init__(self, hyperparameters):\n",
        "      #Hypreparameters\n",
        "      self.learning_rate = hyperparameters[\"learning_rate\"]\n",
        "      self.batch_size_train = hyperparameters[\"train_batch_size\"]\n",
        "      self.batch_size_test = hyperparameters[\"valid_batch_size\"]\n",
        "      self.data_size = hyperparameters[\"data_size\"]\n",
        "      self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "      self.epochs = hyperparameters[\"epochs\"]\n",
        "      \n",
        "      #Dataset\n",
        "      self.initDataset()\n",
        "      self.class_names = [\"bathtub\", \"bed\", \"chair\", \"desk\", \"dresser\", \"monitor\", \"night_stand\", \"sofa\", \"table\", \"toilet\"]\n",
        "      self.num_classes = len(self.class_names)\n",
        "\n",
        "      #Model\n",
        "      self.initModel(hyperparameters)\n",
        "  \n",
        "  def initDataset(self):\n",
        "      self.train_ds = PointCloudData(path, transform=train_transforms)\n",
        "      self.test_ds = PointCloudData(path, valid=True, folder='test', transform=train_transforms)\n",
        "      self.train_dataloader = DataLoader(dataset=self.train_ds, batch_size=self.batch_size_train, shuffle=True, drop_last=True)\n",
        "      self.test_dataloader = DataLoader(dataset=self.test_ds, batch_size=self.batch_size_test)\n",
        "\n",
        "  def initModel(self, hyperparameters):\n",
        "      self.model = PointNet()\n",
        "      print(\"model PointNet was chosen\")\n",
        "      self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "      self.model.to(self.device)\n",
        "      self.opt = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "\n",
        "  def train(self):\n",
        "      self.pred_conf, self.y_conf = [], []                                                           \n",
        "      train_loss_history, valid_loss_history = [], []\n",
        "      train_acc_history, valid_acc_history = [], []\n",
        "      train_accuracy = Accuracy(task='multiclass', num_classes=10)\n",
        "      valid_accuracy = Accuracy(task='multiclass', num_classes=10)\n",
        "\n",
        "      self.num_batch = len(self.train_ds) / self.batch_size_train\n",
        "      print(self.num_batch)\n",
        "\n",
        "      total_time = time.time()\n",
        "\n",
        "      for epoch in range(self.epochs):\n",
        "          t = time.time()\n",
        "\n",
        "          train_loss = []                                                         #track training loss\n",
        "          valid_loss = []\n",
        "          self.model.train()\n",
        "          iterator = tqdm(enumerate(self.train_dataloader, 0))\n",
        "          for i, data in iterator:\n",
        "              inputs, labels = data['pointcloud'].to(self.device).float(), data['category'].to(self.device)\n",
        "\n",
        "              self.opt.zero_grad()\n",
        "              outputs, m3x3, m64x64 = self.model(inputs.transpose(1,2))  # torch.Size([256, 10])\n",
        "              loss = pointnetloss(outputs, labels, m3x3, m64x64)\n",
        "              train_loss.append(loss.cpu().data)\n",
        "              train_accuracy.update(torch.argmax(outputs, 1).cpu(), labels.cpu()) \n",
        "\n",
        "              loss.backward()\n",
        "              self.opt.step()\n",
        "              iterator.set_description(f\"Train loss: {loss.cpu().data}\")\n",
        "                      \n",
        "          with torch.no_grad():\n",
        "            self.model.eval()\n",
        "            for j, sample in tqdm(enumerate(self.test_dataloader, 0)):    \n",
        "                inputs_test, labels_test = sample['pointcloud'].to(self.device).float(), sample['category'].to(self.device)\n",
        "                \n",
        "                outputs_test, m3x3, m64x64  = self.model(inputs_test.transpose(1,2))\n",
        "                loss_test = pointnetloss(outputs_test, labels_test, m3x3, m64x64)\n",
        "                valid_loss.append(loss_test.cpu().data)\n",
        "                valid_accuracy.update(torch.argmax(outputs_test, 1).cpu(), labels_test.cpu())\n",
        "                pred_choice_test = outputs_test.data.max(1)[1]\n",
        "\n",
        "                correct_test = pred_choice_test.eq(labels_test.data).cpu().sum()\n",
        "                self.pred_conf.append(torch.argmax(outputs_test, 1))\n",
        "                self.y_conf.append(labels_test)\n",
        "\n",
        "          #compute confusion matrix\n",
        "          a = torch.cat(self.pred_conf).cpu()\n",
        "          b = torch.cat(self.y_conf).cpu()\n",
        "          confmat = ConfusionMatrix(task='multiclass', num_classes=10, normalize=\"true\")\n",
        "          self.conf_matrix = confmat(a, b)\n",
        "          self.conf_matrix = torch.round(self.conf_matrix, decimals=2)\n",
        "\n",
        "          # total accuracy over all batches\n",
        "          total_train_accuracy = train_accuracy.compute()\n",
        "          total_valid_accuracy = valid_accuracy.compute()\n",
        "          train_accuracy.reset()\n",
        "          valid_accuracy.reset()\n",
        "            \n",
        "          #track loss and acc for plotting\n",
        "          train_loss_history.append(torch.mean(torch.tensor(train_loss)))\n",
        "          valid_loss_history.append(torch.mean(torch.tensor(valid_loss)))\n",
        "          train_acc_history.append(total_train_accuracy)\n",
        "          valid_acc_history.append(total_valid_accuracy)\n",
        "            \n",
        "          elapsed_time_epoch = time.time() - t   \n",
        "            \n",
        "          tmp0 = \"epoch:{:3d} /{:3d}\".format(epoch+1, self.epochs)\n",
        "          tmp1 = \"time: {:.2f} seconds\".format(elapsed_time_epoch)\n",
        "          tmp2 = \"train-loss: {:4.2f}, train-acc: {:.2%}\".format(train_loss_history[epoch], train_acc_history[epoch].item())\n",
        "          tmp3 = \"valid-loss: {:4.2f}, valid-acc: {:.2%}\\n\".format(valid_loss_history[epoch], valid_acc_history[epoch].item())\n",
        "          print(tmp0, tmp1, tmp2, tmp3, sep=\"\\n\")\n",
        "          \n",
        "          #save history\n",
        "          self.history = {\"train_loss\": torch.tensor(train_loss_history), \"train_acc\": torch.tensor(train_acc_history), \n",
        "                          \"valid_loss\": torch.tensor(valid_loss_history), \"valid_acc\": torch.tensor(valid_acc_history)}\n",
        "           \n",
        "  def getHistory(self):\n",
        "      return self.history\n",
        "\n",
        "  def generateConfusionMatrix(self):\n",
        "      fig=plt.figure(figsize = (12,7))\n",
        "      sns.heatmap(self.conf_matrix, annot=True, fmt='g', linewidths=.4, cbar=False)\n",
        "      tick_marks = np.arange(len(self.class_names))\n",
        "      plt.xticks(tick_marks, self.class_names, rotation=45)\n",
        "      plt.yticks(tick_marks, self.class_names, rotation=0)\n",
        "      plt.title(\"Confusion Matrix\")     \n",
        "\n",
        "  def getPerClassAccuracy(self):\n",
        "      per_class_accuracy = 100 * torch.diag(self.conf_matrix) / torch.sum(self.conf_matrix, 1)\n",
        "      tmp = {}\n",
        "      for i, x in enumerate(self.class_names):\n",
        "        tmp[x] = per_class_accuracy[i].item()\n",
        "      print(tmp)\n",
        "    \n",
        "  def showResults(self):\n",
        "      eps = range(0, len(self.history[\"train_loss\"].cpu()))\n",
        "        \n",
        "      sns.set_theme()\n",
        "      fig, ax = plt.subplots(1, 2, figsize=(14, 4))\n",
        "      fig.suptitle('Results')\n",
        "        \n",
        "      ax[0].plot(eps, smooth(self.history[\"train_loss\"].cpu()), 'g', label='Training Loss')\n",
        "      ax[0].plot(eps, smooth(self.history[\"valid_loss\"].cpu()), 'b', label='Valid Loss')\n",
        "      ax[0].set_title('Loss History')\n",
        "      ax[0].set(xlabel='Epochs', ylabel='Loss')\n",
        "      ax[0].legend()\n",
        "        \n",
        "      ax[1].plot(eps, smooth(self.history[\"train_acc\"].cpu()), 'g', label='Training Accuracy')\n",
        "      ax[1].plot(eps, smooth(self.history[\"valid_acc\"].cpu()), 'b', label='Valid Accuracy')\n",
        "      ax[1].set_title('Loss History')\n",
        "      ax[1].set(xlabel='Epochs', ylabel='Accuracy')\n",
        "      ax[1].legend()\n",
        "        \n",
        "  def test_on_missing_data(self, missing_rate=0.5):\n",
        "      test_accuracy = Accuracy(task='multiclass', num_classes=10)\n",
        "        \n",
        "      self.model.eval()\n",
        "      for x, y in self.test_dataloader:\n",
        "          x, y = x.to(self.device), y.to(self.device)\n",
        "            \n",
        "          idc = np.random.choice(32**3, size=(int(32**3*missing_rate)), replace=False)\n",
        "          idc_x = idc%32\n",
        "          idc_y = np.floor_divide(idc, 32)%32\n",
        "          idc_z = np.floor_divide(idc, 32*32)%32\n",
        "          x[:, :, idc_x, idc_y, idc_z] = 0\n",
        "            \n",
        "          pred = self.model(x)\n",
        "          test_accuracy.update(torch.argmax(pred, 1).cpu(), y.cpu())\n",
        "            \n",
        "      return test_accuracy.compute()\n",
        "    \n",
        "  def missing_data_test(self):\n",
        "      acc = []\n",
        "      delta = 200\n",
        "      eps = np.linspace(0,0.99,delta)\n",
        "      for x in eps:\n",
        "          tmp = self.test_on_missing_data(x)\n",
        "          acc.append(tmp)\n",
        "            \n",
        "            \n",
        "      sns.set_theme()\n",
        "      plt.figure(figsize=(8, 4))\n",
        "      plt.plot(eps, smooth(acc))\n",
        "      plt.title(\"Missing Data Test\", size=20, y=1.05)\n",
        "      plt.xlabel(\"missing point ratio\", size=15)\n",
        "      plt.ylabel(\"accuracy\", size=15)\n",
        "      plt.show()"
      ],
      "metadata": {
        "id": "hehPV5pOBS8g"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_hyperparameters = {\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"data_size\": 32,\n",
        "    \"epochs\": 20,\n",
        "    \"train_batch_size\": 32,\n",
        "    \"valid_batch_size\": 64,\n",
        "}    \n",
        "\n",
        "trainer4 = PointNet_Trainer(training_hyperparameters)\n",
        "trainer4.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwH_dwfpCgnO",
        "outputId": "9409c161-2dcc-49f8-f84f-b10593a98846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model PointNet was chosen\n",
            "124.71875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.8409672379493713: : 124it [18:53,  9.14s/it]\n",
            "15it [03:36, 14.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  1 / 20\n",
            "time: 1350.00 seconds\n",
            "train-loss: 1.23, train-acc: 59.15%\n",
            "valid-loss: 1.00, valid-acc: 65.31%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.7934558391571045: : 71it [10:54,  7.68s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download and unzip the dataset ModelNet40\n",
        "\n"
      ],
      "metadata": {
        "id": "2q_oXcDVqwAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://modelnet.cs.princeton.edu/ModelNet40.zip"
      ],
      "metadata": {
        "id": "oZQfBf4noiAG",
        "outputId": "89cf6402-4831-4db1-e740-1215cd5997b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-04 20:40:31--  http://modelnet.cs.princeton.edu/ModelNet40.zip\n",
            "Resolving modelnet.cs.princeton.edu (modelnet.cs.princeton.edu)... 128.112.136.74\n",
            "Connecting to modelnet.cs.princeton.edu (modelnet.cs.princeton.edu)|128.112.136.74|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://modelnet.cs.princeton.edu/ModelNet40.zip [following]\n",
            "--2023-02-04 20:40:31--  https://modelnet.cs.princeton.edu/ModelNet40.zip\n",
            "Connecting to modelnet.cs.princeton.edu (modelnet.cs.princeton.edu)|128.112.136.74|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2039180837 (1.9G) [application/zip]\n",
            "Saving to: ‘ModelNet40.zip’\n",
            "\n",
            "ModelNet40.zip      100%[===================>]   1.90G  60.7MB/s    in 52s     \n",
            "\n",
            "2023-02-04 20:41:23 (37.4 MB/s) - ‘ModelNet40.zip’ saved [2039180837/2039180837]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q ModelNet40.zip;"
      ],
      "metadata": {
        "id": "QB7WT5GUqqXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT = '/content/ModelNet40/'\n",
        "CLASSES = ['airplane', 'bathtub', 'bed', 'bench', 'bookshelf', 'bottle', 'bowl', 'car', 'chair', 'cone',\n",
        "           'cup', 'curtain', 'desk', 'door', 'dresser', 'flower_pot', 'glass_box', 'guitar', 'keyboard', 'lamp',\n",
        "           'laptop', 'mantel', 'monitor', 'night_stand', 'person', 'piano', 'plant', 'radio', 'range_hood', 'sink',\n",
        "           'sofa', 'stairs', 'stool', 'table', 'tent', 'toilet', 'tv_stand', 'vase', 'wardrobe', 'xbox']\n",
        "\n",
        "X = {'train': [], 'test': []}\n",
        "Y = {'train': [], 'test': []}\n",
        "\n",
        "for label, cl in enumerate(CLASSES):\n",
        "    for split in ['train', 'test']:\n",
        "        examples_dir = os.path.join(ROOT, cl, split)\n",
        "        for example in tqdm(os.listdir(examples_dir)):\n",
        "          voxel_index = []\n",
        "          if 'off' in example:\n",
        "            mesh = o3d.io.read_triangle_mesh(examples_dir+'/'+example)\n",
        "            mesh.scale(1 / np.max(mesh.get_max_bound() - mesh.get_min_bound()), center=mesh.get_center())\n",
        "            voxel_grid = o3d.geometry.VoxelGrid.create_from_triangle_mesh(mesh, voxel_size=0.05)\n",
        "            \n",
        "            X[split].append(voxel_grid)\n",
        "            Y[split].append(label)\n"
      ],
      "metadata": {
        "id": "8ztCK1RwpwAt",
        "outputId": "e1d5832d-502f-44ea-d9de-398172dda70e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 626/626 [44:57<00:00,  4.31s/it]\n",
            "  0%|          | 0/100 [00:07<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-c5022fd4d022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mmesh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_triangle_mesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mmesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_max_bound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_min_bound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_center\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mvoxel_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVoxelGrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_from_triangle_mesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoxel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoxel_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DMPVoxNet with Modelnet40"
      ],
      "metadata": {
        "id": "-ohYY7wfQYzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VoxelDataset40(Dataset):\n",
        "    def __init__(self, train = True):\n",
        "      if train:\n",
        "          self.data = X['train']\n",
        "          self.label = Y['train']\n",
        "      else:\n",
        "          self.data = X['test']\n",
        "          self.label = Y['test']\n",
        "        \n",
        "                \n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "\n",
        "    def __preproc__(self, voxels):\n",
        "        \n",
        "        voxel_grid = voxels.get_voxels()\n",
        "        vox_g = np.zeros((32, 32, 32), dtype=np.int32)\n",
        "        for i in range (len(voxel_grid)):\n",
        "          voxel_index = voxel_grid[i].grid_index\n",
        "          vox_g[voxel_index[0],voxel_index[1],voxel_index[2]] = 1\n",
        "\n",
        "        #flip x\n",
        "        if np.random.randint(2):\n",
        "            vox_g = np.flip(vox_g, axis=0)\n",
        "        \n",
        "        #flip y\n",
        "        if np.random.randint(2):\n",
        "            vox_g = np.flip(vox_g, axis=1)\n",
        "        \n",
        "        angle = 360 * np.random.random_sample(1)[0]\n",
        "        vox_g = rotate(vox_g, axes=(0, 1), angle=angle, cval=0.0, reshape=False)  \n",
        "        \n",
        "        return vox_g.copy()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.label[idx]\n",
        "        voxels = self.data[idx]\n",
        "        voxels = self.__preproc__(voxels)\n",
        "        voxels = np.expand_dims(voxels, axis=0)\n",
        "        voxels = torch.tensor(voxels).float()\n",
        "        return voxels, label"
      ],
      "metadata": {
        "id": "GFprPG-DrBQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import SGD, Adam\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from tqdm import tqdm\n",
        "\n",
        "class VoxNet_Trainer40():\n",
        "  def __init__(self, hyperparameters):\n",
        "      #Hypreparameters\n",
        "      self.learning_rate = hyperparameters[\"learning_rate\"]\n",
        "      self.batch_size_train = hyperparameters[\"train_batch_size\"]\n",
        "      self.batch_size_test = hyperparameters[\"valid_batch_size\"]\n",
        "      self.data_size = hyperparameters[\"data_size\"]\n",
        "      self.sgd_momentum = hyperparameters[\"sgd_momentum\"]\n",
        "      self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "      self.epochs = hyperparameters[\"epochs\"]\n",
        "      self.name_model = hyperparameters[\"model\"]\n",
        "      \n",
        "      #Dataset\n",
        "      self.initDataset()\n",
        "      self.class_names = ['airplane', 'bathtub', 'bed', 'bench', 'bookshelf', 'bottle', 'bowl', 'car', 'chair', 'cone',\n",
        "                          'cup', 'curtain', 'desk', 'door', 'dresser', 'flower_pot', 'glass_box', 'guitar', 'keyboard', 'lamp',\n",
        "                          'laptop', 'mantel', 'monitor', 'night_stand', 'person', 'piano', 'plant', 'radio', 'range_hood', 'sink',\n",
        "                          'sofa', 'stairs', 'stool', 'table', 'tent', 'toilet', 'tv_stand', 'vase', 'wardrobe', 'xbox']\n",
        "      self.num_classes = len(self.class_names)\n",
        "\n",
        "      #Model\n",
        "      self.lr_scheduler_step = hyperparameters[\"lr_scheduler_step\"]\n",
        "      self.lr_scheduler_gamma = hyperparameters[\"lr_scheduler_gamma\"]\n",
        "      self.initModel()\n",
        "  \n",
        "  def initDataset(self):\n",
        "      self.train_ds = VoxelDataset40(train=True)\n",
        "      self.test_ds = VoxelDataset40(train=False)\n",
        "      self.train_dataloader = DataLoader(dataset=self.train_ds, batch_size=self.batch_size_train, shuffle=True, drop_last=True)\n",
        "      self.test_dataloader = DataLoader(dataset=self.test_ds, batch_size=self.batch_size_test)\n",
        "\n",
        "  def initModel(self):\n",
        "      self.model = DMPVoxNet40()\n",
        "      os.mkdir('/content/'+str(self.name_model))\n",
        "      print('model DMPVoxNet40 was choosen')\n",
        "      self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "      self.model.to(self.device)\n",
        "      self.opt = SGD(self.model.parameters(), lr=self.learning_rate, momentum=self.sgd_momentum)\n",
        "      self.loss_fn = nn.NLLLoss()\n",
        "      self.lr_scheduler = torch.optim.lr_scheduler.StepLR(self.opt, step_size=self.lr_scheduler_step, gamma=self.lr_scheduler_gamma)\n",
        "\n",
        "  def train(self):\n",
        "      self.pred_conf, self.y_conf = [], []                                                           \n",
        "      train_loss_history, valid_loss_history = [], []\n",
        "      train_acc_history, valid_acc_history = [], []\n",
        "      train_accuracy = Accuracy(task='multiclass', num_classes=40)\n",
        "      valid_accuracy = Accuracy(task='multiclass', num_classes=40)\n",
        "\n",
        "      self.num_batch = len(self.train_ds) / self.batch_size_train\n",
        "      print(self.num_batch)\n",
        "\n",
        "      total_time = time.time()\n",
        "\n",
        "      for epoch in range(self.epochs):\n",
        "          self.lr_scheduler.step()\n",
        "          t = time.time()\n",
        "\n",
        "          train_loss = []                                                         #track training loss\n",
        "          valid_loss = []\n",
        "          self.model.train()\n",
        "          iterator = tqdm(enumerate(self.train_dataloader, 0))\n",
        "          for i, data in iterator:\n",
        "              inputs, labels = data[0], data[1]\n",
        "              inputs = inputs.to(self.device)\n",
        "              labels = labels.to(self.device)\n",
        "\n",
        "              self.opt.zero_grad()\n",
        "              pred = self.model(inputs)  # torch.Size([256, 10])\n",
        "              loss = self.loss_fn(pred,labels)\n",
        "              train_loss.append(loss.cpu().data)\n",
        "              train_accuracy.update(torch.argmax(pred, 1).cpu(), labels.cpu()) \n",
        "\n",
        "              loss.backward()\n",
        "              self.opt.step()\n",
        "              iterator.set_description(f\"Train loss: {loss.cpu().data}\")\n",
        "              \n",
        "              pred_choice = pred.data.max(1)[1]\n",
        "              correct = pred_choice.eq(labels.data).cpu().sum()\n",
        "                      \n",
        "          with torch.no_grad():\n",
        "            self.model.eval()\n",
        "            for j, sample in tqdm(enumerate(self.test_dataloader, 0)):    \n",
        "                inputs_test, labels_test = sample[0], sample[1]\n",
        "                inputs_test = inputs_test.to(self.device)\n",
        "                labels_test = labels_test.to(self.device)\n",
        "                inputs_test = inputs_test.float()  # 转float, torch.Size([256, 1, 32, 32, 32])\n",
        "                \n",
        "                pred_test = self.model(inputs_test)\n",
        "                loss_test = self.loss_fn(pred_test, labels_test)\n",
        "                valid_loss.append(loss_test.cpu().data)\n",
        "                valid_accuracy.update(torch.argmax(pred_test, 1).cpu(), labels_test.cpu())\n",
        "                pred_choice_test = pred_test.data.max(1)[1]\n",
        "\n",
        "                correct_test = pred_choice_test.eq(labels_test.data).cpu().sum()\n",
        "                self.pred_conf.append(torch.argmax(pred_test, 1))\n",
        "                self.y_conf.append(labels_test)\n",
        "\n",
        "          # total accuracy over all batches\n",
        "          total_train_accuracy = train_accuracy.compute()\n",
        "          total_valid_accuracy = valid_accuracy.compute()\n",
        "          train_accuracy.reset()\n",
        "          valid_accuracy.reset()\n",
        "            \n",
        "          #track loss and acc for plotting\n",
        "          train_loss_history.append(torch.mean(torch.tensor(train_loss)))\n",
        "          valid_loss_history.append(torch.mean(torch.tensor(valid_loss)))\n",
        "          train_acc_history.append(total_train_accuracy)\n",
        "          valid_acc_history.append(total_valid_accuracy)\n",
        "            \n",
        "          elapsed_time_epoch = time.time() - t   \n",
        "            \n",
        "          tmp0 = \"epoch:{:3d} /{:3d}\".format(epoch+1, self.epochs)\n",
        "          tmp1 = \"time: {:.2f} seconds\".format(elapsed_time_epoch)\n",
        "          tmp2 = \"train-loss: {:4.2f}, train-acc: {:.2%}\".format(train_loss_history[epoch], train_acc_history[epoch].item())\n",
        "          tmp3 = \"valid-loss: {:4.2f}, valid-acc: {:.2%}\\n\".format(valid_loss_history[epoch], valid_acc_history[epoch].item())\n",
        "          print(tmp0, tmp1, tmp2, tmp3, sep=\"\\n\")\n",
        "\n",
        "\n",
        "          ##save best model \n",
        "          if epoch>1 and total_valid_accuracy>valid_acc_history[-2]:\n",
        "\n",
        "              torch.save({'epoch': epoch+1,\n",
        "                          'model_state_dict': self.model.state_dict(),\n",
        "                          'optimizer_state_dict': self.opt.state_dict(),\n",
        "                          'loss': valid_loss_history[-1], \n",
        "                          'accuracy': total_valid_accuracy},\n",
        "\t                        '/content/'+str(self.name_model)+'/best_model.pth')\n",
        "\n",
        "          \n",
        "          #save history\n",
        "          self.history = {\"train_loss\": torch.tensor(train_loss_history), \"train_acc\": torch.tensor(train_acc_history), \n",
        "                          \"valid_loss\": torch.tensor(valid_loss_history), \"valid_acc\": torch.tensor(valid_acc_history)}\n",
        "           \n",
        "  def getHistory(self):\n",
        "      return self.history\n",
        "\n",
        "  def generateConfusionMatrix(self):\n",
        "      ##load the model\n",
        "      checkpoint = torch.load('/content/'+str(self.name_model)+'/best_model.pth')\n",
        "      self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "      self.opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "      loss = checkpoint['loss']\n",
        "      epoch = checkpoint['epoch']\n",
        "      acc = checkpoint['accuracy']\n",
        "      print('best model was trained at epoch: '+str(epoch))\n",
        "      print('with a validation loss of: '+str(loss.numpy())+' and a validation accuracy of: '+str(acc.numpy()*100))\n",
        "  \n",
        "      ##compute confusion matrix\n",
        "      self.model.eval()\n",
        "      a = torch.cat(self.pred_conf).cpu()\n",
        "      b = torch.cat(self.y_conf).cpu()\n",
        "      confmat = ConfusionMatrix(task='multiclass', num_classes=40, normalize=\"true\")\n",
        "      self.conf_matrix = confmat(a, b)\n",
        "      self.conf_matrix = torch.round(self.conf_matrix, decimals=2)\n",
        "\n",
        "      fig=plt.figure(figsize = (20,12))\n",
        "      sns.heatmap(self.conf_matrix, annot=True, fmt='g', linewidths=.4, cbar=False)\n",
        "      tick_marks = np.arange(len(self.class_names))\n",
        "      plt.xticks(tick_marks, self.class_names, rotation=45)\n",
        "      plt.yticks(tick_marks, self.class_names, rotation=0)\n",
        "      plt.title(\"Confusion Matrix\")     \n",
        "\n",
        "  def getPerClassAccuracy(self):\n",
        "      per_class_accuracy = 100 * torch.diag(self.conf_matrix) / torch.sum(self.conf_matrix, 1)\n",
        "      tmp = {}\n",
        "      for i, x in enumerate(self.class_names):\n",
        "        tmp[x] = per_class_accuracy[i].item()\n",
        "      print(tmp)\n",
        "    \n",
        "  def showResults(self):\n",
        "      eps = range(0, len(self.history[\"train_loss\"].cpu()))\n",
        "        \n",
        "      sns.set_theme()\n",
        "      fig, ax = plt.subplots(1, 2, figsize=(14, 4))\n",
        "      fig.suptitle('Results')\n",
        "        \n",
        "      ax[0].plot(eps, smooth(self.history[\"train_loss\"].cpu()), 'g', label='Training Loss')\n",
        "      ax[0].plot(eps, smooth(self.history[\"valid_loss\"].cpu()), 'b', label='Valid Loss')\n",
        "      ax[0].set_title('Loss History')\n",
        "      ax[0].set(xlabel='Epochs', ylabel='Loss')\n",
        "      ax[0].legend()\n",
        "        \n",
        "      ax[1].plot(eps, smooth(self.history[\"train_acc\"].cpu()), 'g', label='Training Accuracy')\n",
        "      ax[1].plot(eps, smooth(self.history[\"valid_acc\"].cpu()), 'b', label='Valid Accuracy')\n",
        "      ax[1].set_title('Loss History')\n",
        "      ax[1].set(xlabel='Epochs', ylabel='Accuracy')\n",
        "      ax[1].legend()\n",
        "\n",
        "  def draw_voxels(self):\n",
        "      mesh = next(iter(self.train_dataloader))\n",
        "      mesh = mesh[0][0][0]\n",
        "        \n",
        "      ax = plt.figure(figsize=(10,10)).add_subplot(projection='3d')\n",
        "      ax.voxels(mesh, edgecolor='k')\n",
        "      plt.show()\n",
        "        \n",
        "  def test_on_missing_data(self, missing_rate=0.5):\n",
        "      test_accuracy = Accuracy(task='multiclass', num_classes=40)\n",
        "\n",
        "      ##load the model\n",
        "      checkpoint = torch.load('/content/'+str(self.name_model)+'/best_model.pth')\n",
        "      self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "      self.opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "      loss = checkpoint['loss']\n",
        "      epoch = checkpoint['epoch']\n",
        "      acc = checkpoint['accuracy']\n",
        "      print('best model was trained at epoch: '+str(epoch))\n",
        "      print('with a validation loss of: '+str(loss.numpy())+' and a validation accuracy of: '+str(acc.numpy()*100))\n",
        "  \n",
        "      self.model.eval()\n",
        "      for x, y in self.test_dataloader:\n",
        "          x, y = x.to(self.device), y.to(self.device)\n",
        "            \n",
        "          idc = np.random.choice(32**3, size=(int(32**3*missing_rate)), replace=False)\n",
        "          idc_x = idc%32\n",
        "          idc_y = np.floor_divide(idc, 32)%32\n",
        "          idc_z = np.floor_divide(idc, 32*32)%32\n",
        "          x[:, :, idc_x, idc_y, idc_z] = 0\n",
        "            \n",
        "          pred = self.model(x)\n",
        "          test_accuracy.update(torch.argmax(pred, 1).cpu(), y.cpu())\n",
        "            \n",
        "      return test_accuracy.compute()\n",
        "    \n",
        "  def missing_data_test(self):\n",
        "      acc = []\n",
        "      delta = 200\n",
        "      eps = np.linspace(0,0.99,delta)\n",
        "      for x in eps:\n",
        "          tmp = self.test_on_missing_data(x)\n",
        "          acc.append(tmp)\n",
        "            \n",
        "            \n",
        "      sns.set_theme()\n",
        "      plt.figure(figsize=(8, 4))\n",
        "      plt.plot(eps, smooth(acc))\n",
        "      plt.title(\"Missing Data Test\", size=20, y=1.05)\n",
        "      plt.xlabel(\"missing point ratio\", size=15)\n",
        "      plt.ylabel(\"accuracy\", size=15)\n",
        "      plt.show()"
      ],
      "metadata": {
        "id": "4JjB-c7rrFDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "class DMPVoxNet40(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DMPVoxNet40, self).__init__()\n",
        "        n_classes = 40\n",
        "        input_shape = (32,32,32)\n",
        "        self.feat = torch.nn.Sequential(OrderedDict([\n",
        "            ('conv3d_1', torch.nn.Conv3d(in_channels=1, out_channels=32, kernel_size=5, stride=2)),\n",
        "            ('relu1', torch.nn.ReLU()),\n",
        "            ('drop1', torch.nn.Dropout(p=0.2)),\n",
        "            ('conv3d_2', torch.nn.Conv3d(in_channels=32, out_channels=32, kernel_size=3)),\n",
        "            ('relu2', torch.nn.ReLU()),\n",
        "            ('pool2', torch.nn.MaxPool3d(2)),\n",
        "            ('drop2', torch.nn.Dropout(p=0.3)),\n",
        "            ('conv3d_2', torch.nn.Conv3d(in_channels=32, out_channels=128, kernel_size=3)),\n",
        "            ('relu2', torch.nn.ReLU()),\n",
        "            ('pool2', torch.nn.MaxPool3d(2)),\n",
        "            ('drop2', torch.nn.Dropout(p=0.3))\n",
        "        ]))\n",
        "        \n",
        "        x = self.feat(torch.autograd.Variable(torch.rand((1, 1) + input_shape)))\n",
        "        dim_feat = 1\n",
        "        for n in x.size()[1:]:\n",
        "            dim_feat *= n\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(OrderedDict([\n",
        "            ('fc1', torch.nn.Linear(dim_feat, 128)),\n",
        "            ('relu1', torch.nn.ReLU()),\n",
        "            ('drop3', torch.nn.Dropout(p=0.4)),\n",
        "            ('fc2', torch.nn.Linear(128, n_classes))\n",
        "        ]))\n",
        "\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feat(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.mlp(x)\n",
        "        #return x\n",
        "        return self.logsoftmax(x)"
      ],
      "metadata": {
        "id": "AT51SI1JsA8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_hyperparameters = {\n",
        "    \"learning_rate\": 0.1,\n",
        "    \"sgd_momentum\": 0,\n",
        "    \"data_size\": 32,\n",
        "    \"epochs\": 100,\n",
        "    \"lr_scheduler_step\": 16,\n",
        "    \"lr_scheduler_gamma\": 0.7,\n",
        "    \"train_batch_size\": 32,\n",
        "    \"valid_batch_size\": 32,\n",
        "    \"model\" : 'DMPVoxNet40'\n",
        "}    \n",
        "\n",
        "trainer5 = VoxNet_Trainer40(training_hyperparameters)\n",
        "trainer5.train()"
      ],
      "metadata": {
        "id": "77ilFdAdsQtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = np.array([0.2, 0.3, 0.3])\n",
        "b = np.array([0.2, 0.2, 0.2])\n",
        "c = np.array([0.2, 0.2, 0.2])\n",
        "d = [0, 0, 0]\n",
        "e = np.array([0, 0, 0])\n",
        "\n",
        "for i in range(len(c)):\n",
        "  d[i] = a[i]/3+b[i]/3+c[i]/3\n",
        "\n",
        "f = np.array([a, b, c])\n",
        "e = np.einsum('ij->j', f/3)\n",
        "\n",
        "for i in range(0,2):\n",
        "  pred_test = []\n",
        "  print(pred_test)\n",
        "  labels_test = []\n",
        "\n",
        "  for k in range(1):\n",
        "    temp = f\n",
        "    pred_test.append(np.einsum('ij->j', f/3))\n",
        "  print(pred_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2xLU7GPXf3B",
        "outputId": "a7f40ab8-3c1e-444f-98a2-3a0ecb92d821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "[array([0.2       , 0.23333333, 0.23333333])]\n",
            "[]\n",
            "[array([0.2       , 0.23333333, 0.23333333])]\n"
          ]
        }
      ]
    }
  ]
}