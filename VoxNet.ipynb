{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUhO0sYGms7L0HffzjM8Q/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tabba98/neural-network/blob/main/VoxNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "!pip install torchmetrics\n",
        "from torchmetrics.classification import Accuracy\n",
        "from torchmetrics import ConfusionMatrix\n",
        "\n",
        "!pip install open3d;\n",
        "import open3d as o3d\n",
        "\n",
        "#for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import scipy\n",
        "from scipy.ndimage import rotate\n",
        "\n",
        "import time\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "Ic3yD5Ks5Stj",
        "outputId": "588ab8be-bff4-4a66-f2ef-320ee78a4813",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.1+cu116)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting open3d\n",
            "  Downloading open3d-0.16.0-cp38-cp38-manylinux_2_27_x86_64.whl (422.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.5/422.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow>=8.2.0\n",
            "  Downloading Pillow-9.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.8/dist-packages (from open3d) (1.3.5)\n",
            "Collecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: ipywidgets>=7.6.0 in /usr/local/lib/python3.8/dist-packages (from open3d) (7.7.1)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.8/dist-packages (from open3d) (3.2.2)\n",
            "Requirement already satisfied: numpy>1.15 in /usr/local/lib/python3.8/dist-packages (from open3d) (1.21.6)\n",
            "Collecting dash>=2.6.0\n",
            "  Downloading dash-2.8.0-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting configargparse\n",
            "  Downloading ConfigArgParse-1.5.3-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from open3d) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.8/dist-packages (from open3d) (6.0)\n",
            "Collecting nbformat==5.5.0\n",
            "  Downloading nbformat-5.5.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 KB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyquaternion\n",
            "  Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.8/dist-packages (from open3d) (1.0.2)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat==5.5.0->open3d) (2.16.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat==5.5.0->open3d) (4.3.3)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.8/dist-packages (from nbformat==5.5.0->open3d) (5.7.1)\n",
            "Requirement already satisfied: jupyter_core in /usr/local/lib/python3.8/dist-packages (from nbformat==5.5.0->open3d) (5.1.3)\n",
            "Requirement already satisfied: Flask>=1.0.4 in /usr/local/lib/python3.8/dist-packages (from dash>=2.6.0->open3d) (1.1.4)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from dash>=2.6.0->open3d) (5.5.0)\n",
            "Collecting dash-core-components==2.0.0\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting dash-html-components==2.0.0\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Collecting dash-table==5.0.0\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets>=7.6.0->open3d) (3.6.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets>=7.6.0->open3d) (7.9.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets>=7.6.0->open3d) (3.0.5)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets>=7.6.0->open3d) (0.2.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets>=7.6.0->open3d) (5.3.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3->open3d) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3->open3d) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3->open3d) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3->open3d) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0->open3d) (2022.7)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21->open3d) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21->open3d) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21->open3d) (3.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.0.4->dash>=2.6.0->open3d) (7.1.2)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.0.4->dash>=2.6.0->open3d) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.0.4->dash>=2.6.0->open3d) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.0.4->dash>=2.6.0->open3d) (1.1.0)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->open3d) (6.0.4)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->open3d) (6.1.12)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->open3d) (0.2.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->open3d) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->open3d) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->open3d) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->open3d) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->open3d) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->open3d) (57.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat==5.5.0->open3d) (0.19.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat==5.5.0->open3d) (22.2.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat==5.5.0->open3d) (5.10.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (8.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (1.15.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.8/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (5.7.16)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter_core->nbformat==5.5.0->open3d) (2.6.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat==5.5.0->open3d) (3.11.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets>=7.6.0->open3d) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=1.0.4->dash>=2.6.0->open3d) (2.0.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (0.13.3)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (23.2.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (0.15.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (1.8.0)\n",
            "Requirement already satisfied: nbconvert<6.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (5.6.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.6.0->open3d) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython>=4.0.0->ipywidgets>=7.6.0->open3d) (0.7.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (0.6.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (5.0.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (1.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (0.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (0.5.1)\n",
            "Installing collected packages: dash-table, dash-html-components, dash-core-components, addict, pyquaternion, pillow, jedi, configargparse, nbformat, dash, open3d\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: nbformat\n",
            "    Found existing installation: nbformat 5.7.1\n",
            "    Uninstalling nbformat-5.7.1:\n",
            "      Successfully uninstalled nbformat-5.7.1\n",
            "Successfully installed addict-2.4.0 configargparse-1.5.3 dash-2.8.0 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 jedi-0.18.2 nbformat-5.5.0 open3d-0.16.0 pillow-9.4.0 pyquaternion-0.9.9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip"
      ],
      "metadata": {
        "id": "BGBFL8fX5Uuv",
        "outputId": "ce3ed544-8133-47ae-d7bb-975e21f6441f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-25 08:45:43--  http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\n",
            "Resolving 3dvision.princeton.edu (3dvision.princeton.edu)... 128.112.136.74\n",
            "Connecting to 3dvision.princeton.edu (3dvision.princeton.edu)|128.112.136.74|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip [following]\n",
            "--2023-01-25 08:45:43--  https://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\n",
            "Connecting to 3dvision.princeton.edu (3dvision.princeton.edu)|128.112.136.74|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 473402300 (451M) [application/zip]\n",
            "Saving to: ‘ModelNet10.zip’\n",
            "\n",
            "ModelNet10.zip      100%[===================>] 451.47M  88.3MB/s    in 5.8s    \n",
            "\n",
            "2023-01-25 08:45:49 (78.3 MB/s) - ‘ModelNet10.zip’ saved [473402300/473402300]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q ModelNet10.zip;"
      ],
      "metadata": {
        "id": "06P5PcU8L_Xq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "ROOT = '/content/ModelNet10/'\n",
        "CLASSES = ['bathtub', 'bed', 'chair', 'desk', 'dresser', 'monitor', 'night_stand', 'sofa', 'table', 'toilet']\n",
        "\n",
        "X = {'train': [], 'test': []}\n",
        "Y = {'train': [], 'test': []}\n",
        "\n",
        "for label, cl in enumerate(CLASSES):\n",
        "    for split in ['train', 'test']:\n",
        "        examples_dir = os.path.join(ROOT, cl, split)\n",
        "        for example in tqdm(os.listdir(examples_dir)):\n",
        "          voxel_index = []\n",
        "          if 'off' in example:\n",
        "            mesh = o3d.io.read_triangle_mesh(examples_dir+'/'+example)\n",
        "            mesh.scale(1.2 / np.max(mesh.get_max_bound() - mesh.get_min_bound()), center=mesh.get_center())\n",
        "            voxel_grid = o3d.geometry.VoxelGrid.create_from_triangle_mesh(mesh, voxel_size=0.05)\n",
        "            \n",
        "            X[split].append(voxel_grid)\n",
        "            Y[split].append(label)\n"
      ],
      "metadata": {
        "id": "q-fFm_XKMDMH",
        "outputId": "f09fbe7a-e8e0-479c-df7e-630b5b46ce7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 106/106 [00:54<00:00,  1.96it/s]\n",
            "100%|██████████| 50/50 [00:23<00:00,  2.16it/s]\n",
            "100%|██████████| 516/516 [10:09<00:00,  1.18s/it]\n",
            "100%|██████████| 101/101 [01:22<00:00,  1.22it/s]\n",
            "100%|██████████| 890/890 [26:35<00:00,  1.79s/it]\n",
            "100%|██████████| 101/101 [02:28<00:00,  1.47s/it]\n",
            "100%|██████████| 200/200 [01:50<00:00,  1.80it/s]\n",
            "100%|██████████| 86/86 [00:40<00:00,  2.11it/s]\n",
            "100%|██████████| 200/200 [02:48<00:00,  1.19it/s]\n",
            "100%|██████████| 86/86 [01:06<00:00,  1.29it/s]\n",
            "100%|██████████| 465/465 [02:45<00:00,  2.80it/s]\n",
            "100%|██████████| 100/100 [00:34<00:00,  2.92it/s]\n",
            "100%|██████████| 200/200 [02:21<00:00,  1.41it/s]\n",
            "100%|██████████| 86/86 [01:05<00:00,  1.31it/s]\n",
            "100%|██████████| 680/680 [07:39<00:00,  1.48it/s]\n",
            "100%|██████████| 100/100 [01:01<00:00,  1.62it/s]\n",
            "100%|██████████| 392/392 [04:21<00:00,  1.50it/s]\n",
            "100%|██████████| 100/100 [00:23<00:00,  4.23it/s]\n",
            "100%|██████████| 345/345 [10:08<00:00,  1.76s/it]\n",
            "100%|██████████| 101/101 [04:10<00:00,  2.48s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VoxelDataset(Dataset):\n",
        "    def __init__(self, train = True):\n",
        "      if train:\n",
        "          self.data = X['train']\n",
        "          self.label = Y['train']\n",
        "      else:\n",
        "          self.data = X['test']\n",
        "          self.label = Y['test']\n",
        "        \n",
        "                \n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "\n",
        "    def __preproc__(self, voxels):\n",
        "        \n",
        "        voxel_grid = voxels.get_voxels()\n",
        "        vox_g = np.zeros((32, 32, 32), dtype=np.int32)\n",
        "        for i in range (len(voxel_grid)):\n",
        "          voxel_index = voxel_grid[i].grid_index\n",
        "          vox_g[voxel_index[0],voxel_index[1],voxel_index[2]] = 1\n",
        "\n",
        "        #flip x\n",
        "        if np.random.randint(2):\n",
        "            vox_g = np.flip(vox_g, axis=0)\n",
        "        \n",
        "        #flip y\n",
        "        if np.random.randint(2):\n",
        "            vox_g = np.flip(vox_g, axis=1)\n",
        "        \n",
        "        angle = 360 * np.random.random_sample(1)[0]\n",
        "        vox_g = rotate(vox_g, axes=(0, 1), angle=angle, cval=0.0, reshape=False)  \n",
        "        \n",
        "        return vox_g.copy()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.label[idx]\n",
        "        voxels = self.data[idx]\n",
        "        voxels = self.__preproc__(voxels)\n",
        "        voxels = np.expand_dims(voxels, axis=0)\n",
        "        voxels = torch.tensor(voxels).float()\n",
        "        return voxels, label"
      ],
      "metadata": {
        "id": "pfSGCV6k5YXr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "class VoxNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VoxNet, self).__init__()\n",
        "        n_classes = 10\n",
        "        input_shape = (32,32,32)\n",
        "        self.feat = torch.nn.Sequential(OrderedDict([\n",
        "            ('conv3d_1', torch.nn.Conv3d(in_channels=1, out_channels=32, kernel_size=5, stride=2)),\n",
        "            ('relu1', torch.nn.ReLU()),\n",
        "            ('drop1', torch.nn.Dropout(p=0.2)),\n",
        "            ('conv3d_2', torch.nn.Conv3d(in_channels=32, out_channels=32, kernel_size=3)),\n",
        "            ('relu2', torch.nn.ReLU()),\n",
        "            ('pool2', torch.nn.MaxPool3d(2)),\n",
        "            ('drop2', torch.nn.Dropout(p=0.3))\n",
        "        ]))\n",
        "        \n",
        "        x = self.feat(torch.autograd.Variable(torch.rand((1, 1) + input_shape)))\n",
        "        dim_feat = 1\n",
        "        for n in x.size()[1:]:\n",
        "            dim_feat *= n\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(OrderedDict([\n",
        "            ('fc1', torch.nn.Linear(dim_feat, 128)),\n",
        "            ('relu1', torch.nn.ReLU()),\n",
        "            ('drop3', torch.nn.Dropout(p=0.4)),\n",
        "            ('fc2', torch.nn.Linear(128, n_classes))\n",
        "        ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feat(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.mlp(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "BxJn-rxg5thp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "class BatchVoxNet(nn.Module):\n",
        "    def __init__(self, n_classes=10, data_size=32):\n",
        "        super().__init__()\n",
        "        self.n_classes = n_classes\n",
        "        self.data_size = data_size\n",
        "        input_shape = (self.data_size,self.data_size,self.data_size)\n",
        "        self.feat = torch.nn.Sequential(OrderedDict([\n",
        "            ('conv3d_1', torch.nn.Conv3d(in_channels=1, out_channels=32, kernel_size=5, stride=2)),\n",
        "            ('relu1', torch.nn.ReLU()),\n",
        "            #('batch1', torch.nn.BatchNorm3d(32)),\n",
        "            ('drop1', torch.nn.Dropout(p=0.3)),\n",
        "            ('conv3d_2', torch.nn.Conv3d(in_channels=32, out_channels=32, kernel_size=3)),\n",
        "            ('relu2', torch.nn.ReLU()),\n",
        "            #('batch2', torch.nn.BatchNorm3d(32)),\n",
        "            ('pool2', torch.nn.MaxPool3d(2)),\n",
        "            ('drop2', torch.nn.Dropout(p=0.4))\n",
        "        ]))\n",
        "        \n",
        "        x = self.feat(torch.autograd.Variable(torch.rand((1, 1) + input_shape)))\n",
        "        dim_feat = 1\n",
        "        for n in x.size()[1:]:\n",
        "            dim_feat *= n\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(OrderedDict([\n",
        "            ('fc1', torch.nn.Linear(dim_feat, 128)),\n",
        "            ('relu1', torch.nn.ReLU()),\n",
        "            ('drop3', torch.nn.Dropout(p=0.4)),\n",
        "            ('fc2', torch.nn.Linear(128, self.n_classes))\n",
        "        ]))\n",
        "\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feat(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.mlp(x)\n",
        "        return self.logsoftmax(x)"
      ],
      "metadata": {
        "id": "SQEii6FfN2bK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import SGD, Adam\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from tqdm import tqdm\n",
        "\n",
        "class VoxNet_Trainer():\n",
        "  def __init__(self, hyperparameters):\n",
        "      #Hypreparameters\n",
        "      self.learning_rate = hyperparameters[\"learning_rate\"]\n",
        "      self.batch_size_train = hyperparameters[\"train_batch_size\"]\n",
        "      self.batch_size_test = hyperparameters[\"valid_batch_size\"]\n",
        "      self.data_size = hyperparameters[\"data_size\"]\n",
        "      self.sgd_momentum = hyperparameters[\"sgd_momentum\"]\n",
        "      self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "      self.epochs = hyperparameters[\"epochs\"]\n",
        "      \n",
        "      #Dataset\n",
        "      self.initDataset()\n",
        "      self.class_names = [\"bathtub\", \"bed\", \"chair\", \"desk\", \"dresser\", \"monitor\", \"night_stand\", \"sofa\", \"table\", \"toilet\"]\n",
        "      self.num_classes = len(self.class_names)\n",
        "\n",
        "      #Model\n",
        "      self.lr_scheduler_step = hyperparameters[\"lr_scheduler_step\"]\n",
        "      self.lr_scheduler_gamma = hyperparameters[\"lr_scheduler_gamma\"]\n",
        "      self.initModel()\n",
        "  \n",
        "  def initDataset(self):\n",
        "      self.train_ds = VoxelDataset(train=True)\n",
        "      self.test_ds = VoxelDataset(train=False)\n",
        "      self.train_dataloader = DataLoader(dataset=self.train_ds, batch_size=self.batch_size_train, shuffle=True, drop_last=True)\n",
        "      self.test_dataloader = DataLoader(dataset=self.test_ds, batch_size=self.batch_size_test)\n",
        "\n",
        "  def initModel(self):\n",
        "      self.model = BatchVoxNet()\n",
        "      self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "      self.model.to(self.device)\n",
        "      self.opt = SGD(self.model.parameters(), lr=self.learning_rate, momentum=self.sgd_momentum)\n",
        "      self.loss_fn = nn.NLLLoss()\n",
        "      self.lr_scheduler = torch.optim.lr_scheduler.StepLR(self.opt, step_size=self.lr_scheduler_step, gamma=self.lr_scheduler_gamma)\n",
        "\n",
        "  def train(self):\n",
        "      self.pred_conf, self.y_conf = [], []                                                           \n",
        "      train_loss_history, valid_loss_history = [], []\n",
        "      train_acc_history, valid_acc_history = [], []\n",
        "      train_accuracy = Accuracy(task='multiclass', num_classes=10)\n",
        "      valid_accuracy = Accuracy(task='multiclass', num_classes=10)\n",
        "\n",
        "      self.num_batch = len(self.train_ds) / self.batch_size_train\n",
        "      print(self.num_batch)\n",
        "\n",
        "      total_time = time.time()\n",
        "\n",
        "      for epoch in range(self.epochs):\n",
        "          t = time.time()\n",
        "\n",
        "          train_loss = []                                                         #track training loss\n",
        "          valid_loss = []\n",
        "          self.model.train()\n",
        "          iterator = tqdm(enumerate(self.train_dataloader, 0))\n",
        "          for i, data in iterator:\n",
        "              inputs, labels = data[0], data[1]\n",
        "              inputs = inputs.to(self.device)\n",
        "              labels = labels.to(self.device)\n",
        "\n",
        "              self.opt.zero_grad()\n",
        "              pred = self.model(inputs)  # torch.Size([256, 10])\n",
        "              loss = self.loss_fn(pred,labels)\n",
        "              train_loss.append(loss.cpu().data)\n",
        "              train_accuracy.update(torch.argmax(pred, 1).cpu(), labels.cpu()) \n",
        "\n",
        "              loss.backward()\n",
        "              self.opt.step()\n",
        "              self.lr_scheduler.step()\n",
        "              iterator.set_description(f\"Train loss: {loss.cpu().data}\")\n",
        "              \n",
        "              pred_choice = pred.data.max(1)[1]\n",
        "              correct = pred_choice.eq(labels.data).cpu().sum()\n",
        "                      \n",
        "          with torch.no_grad():\n",
        "            self.model.eval()\n",
        "            for j, sample in tqdm(enumerate(self.test_dataloader, 0)):    \n",
        "                inputs_test, labels_test = sample[0], sample[1]\n",
        "                inputs_test = inputs_test.to(self.device)\n",
        "                labels_test = labels_test.to(self.device)\n",
        "                inputs_test = inputs_test.float()  # 转float, torch.Size([256, 1, 32, 32, 32])\n",
        "                \n",
        "                pred_test = self.model(inputs_test)\n",
        "                loss_test = self.loss_fn(pred_test, labels_test)\n",
        "                valid_loss.append(loss_test.cpu().data)\n",
        "                valid_accuracy.update(torch.argmax(pred_test, 1).cpu(), labels_test.cpu())\n",
        "                pred_choice_test = pred_test.data.max(1)[1]\n",
        "\n",
        "                correct_test = pred_choice_test.eq(labels_test.data).cpu().sum()\n",
        "                self.pred_conf.append(torch.argmax(pred_test, 1))\n",
        "                self.y_conf.append(labels_test)\n",
        "\n",
        "          #compute confusion matrix\n",
        "          a = torch.cat(self.pred_conf).cpu()\n",
        "          b = torch.cat(self.y_conf).cpu()\n",
        "          confmat = ConfusionMatrix(task='multiclass', num_classes=10, normalize=\"true\")\n",
        "          self.conf_matrix = confmat(a, b)\n",
        "          self.conf_matrix = torch.round(self.conf_matrix, decimals=2)\n",
        "\n",
        "          # total accuracy over all batches\n",
        "          total_train_accuracy = train_accuracy.compute()\n",
        "          total_valid_accuracy = valid_accuracy.compute()\n",
        "          train_accuracy.reset()\n",
        "          valid_accuracy.reset()\n",
        "            \n",
        "          #track loss and acc for plotting\n",
        "          train_loss_history.append(torch.mean(torch.tensor(train_loss)))\n",
        "          valid_loss_history.append(torch.mean(torch.tensor(valid_loss)))\n",
        "          train_acc_history.append(total_train_accuracy)\n",
        "          valid_acc_history.append(total_valid_accuracy)\n",
        "            \n",
        "          elapsed_time_epoch = time.time() - t   \n",
        "            \n",
        "          tmp0 = \"epoch:{:3d} /{:3d}\".format(epoch+1, self.epochs)\n",
        "          tmp1 = \"time: {:.2f} seconds\".format(elapsed_time_epoch)\n",
        "          tmp2 = \"train-loss: {:4.2f}, train-acc: {:.2%}\".format(train_loss_history[epoch], train_acc_history[epoch].item())\n",
        "          tmp3 = \"valid-loss: {:4.2f}, valid-acc: {:.2%}\\n\".format(valid_loss_history[epoch], valid_acc_history[epoch].item())\n",
        "          print(tmp0, tmp1, tmp2, tmp3, sep=\"\\n\")\n",
        "          \n",
        "          #save history\n",
        "          self.history = {\"train_loss\": torch.tensor(train_loss_history), \"train_acc\": torch.tensor(train_acc_history), \n",
        "                          \"valid_loss\": torch.tensor(valid_loss_history), \"valid_acc\": torch.tensor(valid_acc_history)}\n",
        "           \n",
        "        \n",
        "  def generateConfusionMatrix(self):\n",
        "      fig=plt.figure(figsize = (12,7))\n",
        "      sns.heatmap(self.conf_matrix, annot=True, fmt='g', linewidths=.4, cbar=False)\n",
        "      tick_marks = np.arange(len(self.class_names))\n",
        "      plt.xticks(tick_marks, self.class_names, rotation=45)\n",
        "      plt.yticks(tick_marks, self.class_names, rotation=0)\n",
        "      plt.title(\"Confusion Matrix\")     \n",
        "\n",
        "  def getPerClassAccuracy(self):\n",
        "      per_class_accuracy = 100 * torch.diag(self.conf_matrix) / torch.sum(self.conf_matrix, 1)\n",
        "      tmp = {}\n",
        "      for i, x in enumerate(self.class_names):\n",
        "        tmp[x] = per_class_accuracy[i].item()\n",
        "      print(tmp)\n",
        "    \n",
        "  def showResults(self):\n",
        "      eps = range(0, len(self.history[\"train_loss\"].cpu()))\n",
        "        \n",
        "      sns.set_theme()\n",
        "      fig, ax = plt.subplots(1, 2, figsize=(14, 4))\n",
        "      fig.suptitle('Results')\n",
        "        \n",
        "      ax[0].plot(eps, smooth(self.history[\"train_loss\"].cpu()), 'g', label='Training Loss')\n",
        "      ax[0].plot(eps, smooth(self.history[\"valid_loss\"].cpu()), 'b', label='Valid Loss')\n",
        "      ax[0].set_title('Loss History')\n",
        "      ax[0].set(xlabel='Epochs', ylabel='Loss')\n",
        "      ax[0].legend()\n",
        "        \n",
        "      ax[1].plot(eps, smooth(self.history[\"train_acc\"].cpu()), 'g', label='Training Accuracy')\n",
        "      ax[1].plot(eps, smooth(self.history[\"valid_acc\"].cpu()), 'b', label='Valid Accuracy')\n",
        "      ax[1].set_title('Loss History')\n",
        "      ax[1].set(xlabel='Epochs', ylabel='Accuracy')\n",
        "      ax[1].legend()\n",
        "\n",
        "  def draw_voxels(self):\n",
        "      mesh = next(iter(self.train_dataloader))\n",
        "      mesh = mesh[0][0][0]\n",
        "        \n",
        "      ax = plt.figure(figsize=(10,10)).add_subplot(projection='3d')\n",
        "      ax.voxels(mesh, edgecolor='k')\n",
        "      plt.show()\n",
        "        \n",
        "  def test_on_missing_data(self, missing_rate=0.5):\n",
        "      test_accuracy = Accuracy(task='multiclass', num_classes=10)\n",
        "        \n",
        "      self.model.eval()\n",
        "      for x, y in self.test_dataloader:\n",
        "          x, y = x.to(self.device), y.to(self.device)\n",
        "            \n",
        "          idc = np.random.choice(32**3, size=(int(32**3*missing_rate)), replace=False)\n",
        "          idc_x = idc%32\n",
        "          idc_y = np.floor_divide(idc, 32)%32\n",
        "          idc_z = np.floor_divide(idc, 32*32)%32\n",
        "          x[:, :, idc_x, idc_y, idc_z] = 0\n",
        "            \n",
        "          pred = self.model(x)\n",
        "          test_accuracy.update(torch.argmax(pred, 1).cpu(), y.cpu())\n",
        "            \n",
        "      return test_accuracy.compute()\n",
        "    \n",
        "  def missing_data_test(self):\n",
        "      acc = []\n",
        "      delta = 200\n",
        "      eps = np.linspace(0,0.99,delta)\n",
        "      for x in eps:\n",
        "          tmp = self.test_on_missing_data(x)\n",
        "          acc.append(tmp)\n",
        "            \n",
        "            \n",
        "      sns.set_theme()\n",
        "      plt.figure(figsize=(8, 4))\n",
        "      plt.plot(eps, smooth(acc))\n",
        "      plt.title(\"Missing Data Test\", size=20, y=1.05)\n",
        "      plt.xlabel(\"missing point ratio\", size=15)\n",
        "      plt.ylabel(\"accuracy\", size=15)\n",
        "      plt.show()"
      ],
      "metadata": {
        "id": "hX_KJavxavhZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_hyperparameters = {\n",
        "    \"learning_rate\": 0.1,\n",
        "    \"sgd_momentum\": 0.9,\n",
        "    \"data_size\": 32,\n",
        "    \"epochs\": 30,\n",
        "    \"lr_scheduler_step\": 20,\n",
        "    \"lr_scheduler_gamma\": 0.5,\n",
        "    \"train_batch_size\": 32,\n",
        "    \"valid_batch_size\": 32\n",
        "}    \n",
        "\n",
        "trainer = VoxNet_Trainer(training_hyperparameters)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "HBhOIt8Emq1B",
        "outputId": "46443fc3-e923-4f2e-edf0-76563ace1e9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31.1796875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 1.385017991065979: : 31it [01:35,  3.09s/it]\n",
            "8it [00:15,  1.88s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  1 / 30\n",
            "time: 110.72 seconds\n",
            "train-loss: 1.71, train-acc: 41.43%\n",
            "valid-loss: 1.41, valid-acc: 47.58%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 1.1543529033660889: : 31it [01:32,  2.97s/it]\n",
            "8it [00:12,  1.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  2 / 30\n",
            "time: 105.13 seconds\n",
            "train-loss: 1.15, train-acc: 60.23%\n",
            "valid-loss: 1.11, valid-acc: 59.80%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.9473156332969666: : 31it [01:32,  2.99s/it]\n",
            "8it [00:12,  1.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  3 / 30\n",
            "time: 105.56 seconds\n",
            "train-loss: 0.99, train-acc: 66.81%\n",
            "valid-loss: 1.07, valid-acc: 63.22%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 1.0501444339752197: : 31it [01:35,  3.09s/it]\n",
            "8it [00:12,  1.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  4 / 30\n",
            "time: 108.65 seconds\n",
            "train-loss: 0.91, train-acc: 69.93%\n",
            "valid-loss: 1.01, valid-acc: 64.43%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.7335987687110901: : 31it [01:31,  2.94s/it]\n",
            "8it [00:12,  1.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  5 / 30\n",
            "time: 104.10 seconds\n",
            "train-loss: 0.89, train-acc: 70.34%\n",
            "valid-loss: 1.01, valid-acc: 63.99%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 1.0297675132751465: : 31it [01:30,  2.93s/it]\n",
            "8it [00:12,  1.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  6 / 30\n",
            "time: 103.58 seconds\n",
            "train-loss: 0.88, train-acc: 70.64%\n",
            "valid-loss: 0.99, valid-acc: 66.30%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.6410996317863464: : 31it [01:34,  3.04s/it]\n",
            "8it [00:13,  1.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  7 / 30\n",
            "time: 107.39 seconds\n",
            "train-loss: 0.88, train-acc: 71.02%\n",
            "valid-loss: 0.99, valid-acc: 66.19%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.8539220094680786: : 31it [01:31,  2.94s/it]\n",
            "8it [00:12,  1.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  8 / 30\n",
            "time: 104.05 seconds\n",
            "train-loss: 0.86, train-acc: 70.14%\n",
            "valid-loss: 1.00, valid-acc: 66.96%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.71344393491745: : 31it [01:35,  3.08s/it]\n",
            "8it [00:12,  1.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  9 / 30\n",
            "time: 108.28 seconds\n",
            "train-loss: 0.87, train-acc: 70.36%\n",
            "valid-loss: 0.98, valid-acc: 66.63%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.9174046516418457: : 5it [00:23,  4.64s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-4ae25ed5343c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVoxNet_Trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_hyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-3a7eb621204f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m               \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m               \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def smooth(x, w=0):\n",
        "    last = x[0]\n",
        "    smoothed = []\n",
        "    for point in x:\n",
        "      smoothed_val = w * last + (1 - w) * point\n",
        "      smoothed.append(smoothed_val)\n",
        "      ast = smoothed_val\n",
        "          \n",
        "    return smoothed\n",
        "\n",
        "trainer.showResults()"
      ],
      "metadata": {
        "id": "N7DHiwXimwKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.generateConfusionMatrix()"
      ],
      "metadata": {
        "id": "yr5CE5Zjw9Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.getPerClassAccuracy()"
      ],
      "metadata": {
        "id": "zTsndYBB95vT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.missing_data_test()"
      ],
      "metadata": {
        "id": "s30abd-s2seu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.draw_voxels()"
      ],
      "metadata": {
        "id": "3vp-GeB2xdit"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}