{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdnGwHsnWW8VvGgRBVmobO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tabba98/neural-network/blob/main/VoxNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "!pip install torchmetrics\n",
        "from torchmetrics.classification import Accuracy\n",
        "from torchmetrics import ConfusionMatrix\n",
        "\n",
        "!pip install open3d;\n",
        "import open3d as o3d\n",
        "\n",
        "#for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import scipy\n",
        "from scipy.ndimage import rotate\n",
        "\n",
        "import time\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "Ic3yD5Ks5Stj",
        "outputId": "7bfb8748-e09b-4f2f-d160-516ef01bcafa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.1+cu116)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting open3d\n",
            "  Downloading open3d-0.16.0-cp38-cp38-manylinux_2_27_x86_64.whl (422.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.5/422.5 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: ipywidgets>=7.6.0 in /usr/local/lib/python3.8/dist-packages (from open3d) (7.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from open3d) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.8/dist-packages (from open3d) (6.0)\n",
            "Requirement already satisfied: numpy>1.15 in /usr/local/lib/python3.8/dist-packages (from open3d) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.8/dist-packages (from open3d) (1.0.2)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.8/dist-packages (from open3d) (1.3.5)\n",
            "Collecting pillow>=8.2.0\n",
            "  Downloading Pillow-9.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.8/dist-packages (from open3d) (3.2.2)\n",
            "Collecting nbformat==5.5.0\n",
            "  Downloading nbformat-5.5.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dash>=2.6.0\n",
            "  Downloading dash-2.8.0-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyquaternion\n",
            "  Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
            "Collecting configargparse\n",
            "  Downloading ConfigArgParse-1.5.3-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat==5.5.0->open3d) (2.16.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat==5.5.0->open3d) (4.3.3)\n",
            "Requirement already satisfied: jupyter_core in /usr/local/lib/python3.8/dist-packages (from nbformat==5.5.0->open3d) (5.1.3)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.8/dist-packages (from nbformat==5.5.0->open3d) (5.7.1)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from dash>=2.6.0->open3d) (5.5.0)\n",
            "Collecting dash-html-components==2.0.0\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Collecting dash-core-components==2.0.0\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting dash-table==5.0.0\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Requirement already satisfied: Flask>=1.0.4 in /usr/local/lib/python3.8/dist-packages (from dash>=2.6.0->open3d) (1.1.4)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets>=7.6.0->open3d) (0.2.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets>=7.6.0->open3d) (5.3.4)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets>=7.6.0->open3d) (3.6.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets>=7.6.0->open3d) (7.9.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets>=7.6.0->open3d) (3.0.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3->open3d) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3->open3d) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3->open3d) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3->open3d) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0->open3d) (2022.7)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21->open3d) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21->open3d) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21->open3d) (3.1.0)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.0.4->dash>=2.6.0->open3d) (1.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.0.4->dash>=2.6.0->open3d) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.0.4->dash>=2.6.0->open3d) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.0.4->dash>=2.6.0->open3d) (2.11.3)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->open3d) (6.0.4)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->open3d) (6.1.12)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->open3d) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->open3d) (2.0.10)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->open3d) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->open3d) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->open3d) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->open3d) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->open3d) (57.4.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat==5.5.0->open3d) (5.10.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat==5.5.0->open3d) (0.19.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat==5.5.0->open3d) (22.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (1.15.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (8.1.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.8/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (5.7.16)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter_core->nbformat==5.5.0->open3d) (2.6.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat==5.5.0->open3d) (3.11.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets>=7.6.0->open3d) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=1.0.4->dash>=2.6.0->open3d) (2.0.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (0.15.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (0.13.3)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (23.2.1)\n",
            "Requirement already satisfied: nbconvert<6.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (1.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.6.0->open3d) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython>=4.0.0->ipywidgets>=7.6.0->open3d) (0.7.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (0.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (5.0.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (0.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (0.8.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.0->open3d) (0.5.1)\n",
            "Installing collected packages: dash-table, dash-html-components, dash-core-components, addict, pyquaternion, pillow, jedi, configargparse, nbformat, dash, open3d\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: nbformat\n",
            "    Found existing installation: nbformat 5.7.1\n",
            "    Uninstalling nbformat-5.7.1:\n",
            "      Successfully uninstalled nbformat-5.7.1\n",
            "Successfully installed addict-2.4.0 configargparse-1.5.3 dash-2.8.0 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 jedi-0.18.2 nbformat-5.5.0 open3d-0.16.0 pillow-9.4.0 pyquaternion-0.9.9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip"
      ],
      "metadata": {
        "id": "BGBFL8fX5Uuv",
        "outputId": "1200bd2c-29f8-4ec5-e5e8-f83ea9f2e677",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-24 20:39:37--  http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\n",
            "Resolving 3dvision.princeton.edu (3dvision.princeton.edu)... 128.112.136.74\n",
            "Connecting to 3dvision.princeton.edu (3dvision.princeton.edu)|128.112.136.74|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip [following]\n",
            "--2023-01-24 20:39:37--  https://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\n",
            "Connecting to 3dvision.princeton.edu (3dvision.princeton.edu)|128.112.136.74|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 473402300 (451M) [application/zip]\n",
            "Saving to: ‘ModelNet10.zip’\n",
            "\n",
            "ModelNet10.zip      100%[===================>] 451.47M   109MB/s    in 4.2s    \n",
            "\n",
            "2023-01-24 20:39:42 (108 MB/s) - ‘ModelNet10.zip’ saved [473402300/473402300]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q ModelNet10.zip;"
      ],
      "metadata": {
        "id": "06P5PcU8L_Xq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "ROOT = '/content/ModelNet10/'\n",
        "CLASSES = ['bathtub', 'bed', 'chair', 'desk', 'dresser', 'monitor', 'night_stand', 'sofa', 'table', 'toilet']\n",
        "\n",
        "X = {'train': [], 'test': []}\n",
        "Y = {'train': [], 'test': []}\n",
        "\n",
        "for label, cl in enumerate(CLASSES):\n",
        "    for split in ['train', 'test']:\n",
        "        examples_dir = os.path.join(ROOT, cl, split)\n",
        "        for example in tqdm(os.listdir(examples_dir)):\n",
        "          voxel_index = []\n",
        "          if 'off' in example:\n",
        "            mesh = o3d.io.read_triangle_mesh(examples_dir+'/'+example)\n",
        "            mesh.scale(1.2 / np.max(mesh.get_max_bound() - mesh.get_min_bound()), center=mesh.get_center())\n",
        "            voxel_grid = o3d.geometry.VoxelGrid.create_from_triangle_mesh(mesh, voxel_size=0.05)\n",
        "            \n",
        "            X[split].append(voxel_grid)\n",
        "            Y[split].append(label)\n"
      ],
      "metadata": {
        "id": "q-fFm_XKMDMH",
        "outputId": "2f2b4ccc-8a69-4df3-8446-712c9b247a1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 106/106 [00:41<00:00,  2.53it/s]\n",
            "100%|██████████| 50/50 [00:17<00:00,  2.82it/s]\n",
            "100%|██████████| 516/516 [07:42<00:00,  1.12it/s]\n",
            "100%|██████████| 101/101 [01:00<00:00,  1.67it/s]\n",
            "100%|██████████| 890/890 [20:24<00:00,  1.38s/it]\n",
            "100%|██████████| 101/101 [01:54<00:00,  1.14s/it]\n",
            "100%|██████████| 200/200 [01:25<00:00,  2.35it/s]\n",
            "100%|██████████| 86/86 [00:31<00:00,  2.70it/s]\n",
            "100%|██████████| 200/200 [02:12<00:00,  1.51it/s]\n",
            "100%|██████████| 86/86 [00:52<00:00,  1.65it/s]\n",
            "100%|██████████| 465/465 [02:07<00:00,  3.65it/s]\n",
            "100%|██████████| 100/100 [00:24<00:00,  4.16it/s]\n",
            "100%|██████████| 200/200 [01:52<00:00,  1.78it/s]\n",
            "100%|██████████| 86/86 [00:51<00:00,  1.68it/s]\n",
            "100%|██████████| 680/680 [05:52<00:00,  1.93it/s]\n",
            "100%|██████████| 100/100 [00:48<00:00,  2.06it/s]\n",
            "100%|██████████| 392/392 [03:30<00:00,  1.86it/s]\n",
            "100%|██████████| 100/100 [00:18<00:00,  5.34it/s]\n",
            "100%|██████████| 345/345 [07:57<00:00,  1.38s/it]\n",
            "100%|██████████| 101/101 [03:15<00:00,  1.94s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VoxelDataset(Dataset):\n",
        "    def __init__(self, train = True):\n",
        "      if train:\n",
        "          self.data = X['train']\n",
        "          self.label = Y['train']\n",
        "      else:\n",
        "          self.data = X['test']\n",
        "          self.label = Y['test']\n",
        "        \n",
        "                \n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "\n",
        "    def __preproc__(self, voxels):\n",
        "        \n",
        "        voxel_grid = voxels.get_voxels()\n",
        "        vox_g = np.zeros((32, 32, 32), dtype=np.int32)\n",
        "        for i in range (len(voxel_grid)):\n",
        "          voxel_index = voxel_grid[i].grid_index\n",
        "          vox_g[voxel_index[0],voxel_index[1],voxel_index[2]] = 1\n",
        "\n",
        "        #flip x\n",
        "        if np.random.randint(2):\n",
        "            vox_g = np.flip(vox_g, axis=0)\n",
        "        \n",
        "        #flip y\n",
        "        if np.random.randint(2):\n",
        "            vox_g = np.flip(vox_g, axis=1)\n",
        "        \n",
        "        angle = 360 * np.random.random_sample(1)[0]\n",
        "        vox_g = rotate(vox_g, axes=(0, 1), angle=angle, cval=0.0, reshape=False)  \n",
        "        \n",
        "        return vox_g.copy()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.label[idx]\n",
        "        voxels = self.data[idx]\n",
        "        voxels = self.__preproc__(voxels)\n",
        "        voxels = np.expand_dims(voxels, axis=0)\n",
        "        voxels = torch.tensor(voxels).float()\n",
        "        return voxels, label"
      ],
      "metadata": {
        "id": "pfSGCV6k5YXr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "class VoxNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VoxNet, self).__init__()\n",
        "        n_classes = 10\n",
        "        input_shape = (32,32,32)\n",
        "        self.feat = torch.nn.Sequential(OrderedDict([\n",
        "            ('conv3d_1', torch.nn.Conv3d(in_channels=1, out_channels=32, kernel_size=5, stride=2)),\n",
        "            ('relu1', torch.nn.ReLU()),\n",
        "            ('drop1', torch.nn.Dropout(p=0.2)),\n",
        "            ('conv3d_2', torch.nn.Conv3d(in_channels=32, out_channels=32, kernel_size=3)),\n",
        "            ('relu2', torch.nn.ReLU()),\n",
        "            ('pool2', torch.nn.MaxPool3d(2)),\n",
        "            ('drop2', torch.nn.Dropout(p=0.3))\n",
        "        ]))\n",
        "        \n",
        "        x = self.feat(torch.autograd.Variable(torch.rand((1, 1) + input_shape)))\n",
        "        dim_feat = 1\n",
        "        for n in x.size()[1:]:\n",
        "            dim_feat *= n\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(OrderedDict([\n",
        "            ('fc1', torch.nn.Linear(dim_feat, 128)),\n",
        "            ('relu1', torch.nn.ReLU()),\n",
        "            ('drop3', torch.nn.Dropout(p=0.4)),\n",
        "            ('fc2', torch.nn.Linear(128, n_classes))\n",
        "        ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feat(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.mlp(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "BxJn-rxg5thp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "class BatchVoxNet(nn.Module):\n",
        "    def __init__(self, n_classes=10, data_size=32):\n",
        "        super().__init__()\n",
        "        self.n_classes = n_classes\n",
        "        self.data_size = data_size\n",
        "        input_shape = (self.data_size,self.data_size,self.data_size)\n",
        "        self.feat = torch.nn.Sequential(OrderedDict([\n",
        "            ('conv3d_1', torch.nn.Conv3d(in_channels=1, out_channels=32, kernel_size=5, stride=2)),\n",
        "            ('relu1', torch.nn.ReLU()),\n",
        "            ('batch1', torch.nn.BatchNorm3d(32)),\n",
        "            ('drop1', torch.nn.Dropout(p=0.3)),\n",
        "            ('conv3d_2', torch.nn.Conv3d(in_channels=32, out_channels=32, kernel_size=3)),\n",
        "            ('relu2', torch.nn.ReLU()),\n",
        "            #('batch2', torch.nn.BatchNorm3d(32)),\n",
        "            ('pool2', torch.nn.MaxPool3d(2)),\n",
        "            ('drop2', torch.nn.Dropout(p=0.4))\n",
        "        ]))\n",
        "        \n",
        "        x = self.feat(torch.autograd.Variable(torch.rand((1, 1) + input_shape)))\n",
        "        dim_feat = 1\n",
        "        for n in x.size()[1:]:\n",
        "            dim_feat *= n\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(OrderedDict([\n",
        "            ('fc1', torch.nn.Linear(dim_feat, 128)),\n",
        "            ('relu1', torch.nn.ReLU()),\n",
        "            ('drop3', torch.nn.Dropout(p=0.4)),\n",
        "            ('fc2', torch.nn.Linear(128, self.n_classes))\n",
        "        ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feat(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.mlp(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "SQEii6FfN2bK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import SGD, Adam\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from tqdm import tqdm\n",
        "\n",
        "class VoxNet_Trainer():\n",
        "  def __init__(self, hyperparameters):\n",
        "      #Hypreparameters\n",
        "      self.learning_rate = hyperparameters[\"learning_rate\"]\n",
        "      self.batch_size_train = hyperparameters[\"train_batch_size\"]\n",
        "      self.batch_size_test = hyperparameters[\"valid_batch_size\"]\n",
        "      self.data_size = hyperparameters[\"data_size\"]\n",
        "      self.sgd_momentum = hyperparameters[\"sgd_momentum\"]\n",
        "      self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "      self.epochs = hyperparameters[\"epochs\"]\n",
        "      \n",
        "      #Dataset\n",
        "      self.initDataset()\n",
        "      self.class_names = [\"bathtub\", \"bed\", \"chair\", \"desk\", \"dresser\", \"monitor\", \"night_stand\", \"sofa\", \"table\", \"toilet\"]\n",
        "      self.num_classes = len(self.class_names)\n",
        "\n",
        "      #Model\n",
        "      self.initModel()\n",
        "  \n",
        "  def initDataset(self):\n",
        "      self.train_ds = VoxelDataset(train=True)\n",
        "      self.test_ds = VoxelDataset(train=False)\n",
        "      self.train_dataloader = DataLoader(dataset=self.train_ds, batch_size=self.batch_size_train, shuffle=True, drop_last=True)\n",
        "      self.test_dataloader = DataLoader(dataset=self.test_ds, batch_size=self.batch_size_test)\n",
        "\n",
        "  def initModel(self):\n",
        "      self.model = BatchVoxNet()\n",
        "      self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "      self.model.to(self.device)\n",
        "      self.opt = SGD(self.model.parameters(), lr=self.learning_rate, momentum=self.sgd_momentum)\n",
        "      self.loss_fn = F.cross_entropy\n",
        "\n",
        "  def train(self):\n",
        "      self.pred_conf, self.y_conf = [], []                                                           \n",
        "      train_loss_history, valid_loss_history = [], []\n",
        "      train_acc_history, valid_acc_history = [], []\n",
        "      train_accuracy = Accuracy(task='multiclass', num_classes=10)\n",
        "      valid_accuracy = Accuracy(task='multiclass', num_classes=10)\n",
        "\n",
        "      self.num_batch = len(self.train_ds) / self.batch_size_train\n",
        "      print(self.num_batch)\n",
        "\n",
        "      total_time = time.time()\n",
        "\n",
        "      for epoch in range(self.epochs):\n",
        "          t = time.time()\n",
        "\n",
        "          train_loss = []                                                         #track training loss\n",
        "          valid_loss = []\n",
        "          self.model.train()\n",
        "          iterator = tqdm(enumerate(self.train_dataloader, 0))\n",
        "          for i, data in iterator:\n",
        "              inputs, labels = data[0], data[1]\n",
        "              inputs = inputs.to(self.device)\n",
        "              labels = labels.to(self.device)\n",
        "\n",
        "              self.opt.zero_grad()\n",
        "              pred = self.model(inputs)  # torch.Size([256, 10])\n",
        "              loss = self.loss_fn(pred,labels)\n",
        "              train_loss.append(loss.cpu().data)\n",
        "              train_accuracy.update(torch.argmax(pred, 1).cpu(), labels.cpu()) \n",
        "\n",
        "              loss.backward()\n",
        "              self.opt.step()\n",
        "              iterator.set_description(f\"Train loss: {loss.cpu().data}\")\n",
        "              \n",
        "              pred_choice = pred.data.max(1)[1]\n",
        "              correct = pred_choice.eq(labels.data).cpu().sum()\n",
        "                      \n",
        "          with torch.no_grad():\n",
        "            self.model.eval()\n",
        "            for j, sample in tqdm(enumerate(self.test_dataloader, 0)):    \n",
        "                inputs_test, labels_test = sample[0], sample[1]\n",
        "                inputs_test = inputs_test.to(self.device)\n",
        "                labels_test = labels_test.to(self.device)\n",
        "                inputs_test = inputs_test.float()  # 转float, torch.Size([256, 1, 32, 32, 32])\n",
        "                \n",
        "                pred_test = self.model(inputs_test)\n",
        "                loss_test = self.loss_fn(pred_test, labels_test)\n",
        "                valid_loss.append(loss_test.cpu().data)\n",
        "                valid_accuracy.update(torch.argmax(pred_test, 1).cpu(), labels_test.cpu())\n",
        "                pred_choice_test = pred_test.data.max(1)[1]\n",
        "\n",
        "                correct_test = pred_choice_test.eq(labels_test.data).cpu().sum()\n",
        "                self.pred_conf.append(torch.argmax(pred_test, 1))\n",
        "                self.y_conf.append(labels_test)\n",
        "\n",
        "          #compute confusion matrix\n",
        "          a = torch.cat(self.pred_conf).cpu()\n",
        "          b = torch.cat(self.y_conf).cpu()\n",
        "          confmat = ConfusionMatrix(task='multiclass', num_classes=10, normalize=\"true\")\n",
        "          self.conf_matrix = confmat(a, b)\n",
        "          self.conf_matrix = torch.round(self.conf_matrix, decimals=2)\n",
        "\n",
        "          # total accuracy over all batches\n",
        "          total_train_accuracy = train_accuracy.compute()\n",
        "          total_valid_accuracy = valid_accuracy.compute()\n",
        "          train_accuracy.reset()\n",
        "          valid_accuracy.reset()\n",
        "            \n",
        "          #track loss and acc for plotting\n",
        "          train_loss_history.append(torch.mean(torch.tensor(train_loss)))\n",
        "          valid_loss_history.append(torch.mean(torch.tensor(valid_loss)))\n",
        "          train_acc_history.append(total_train_accuracy)\n",
        "          valid_acc_history.append(total_valid_accuracy)\n",
        "            \n",
        "          elapsed_time_epoch = time.time() - t   \n",
        "            \n",
        "          tmp0 = \"epoch:{:3d} /{:3d}\".format(epoch+1, self.epochs)\n",
        "          tmp1 = \"time: {:.2f} seconds\".format(elapsed_time_epoch)\n",
        "          tmp2 = \"train-loss: {:4.2f}, train-acc: {:.2%}\".format(train_loss_history[epoch], train_acc_history[epoch].item())\n",
        "          tmp3 = \"valid-loss: {:4.2f}, valid-acc: {:.2%}\\n\".format(valid_loss_history[epoch], valid_acc_history[epoch].item())\n",
        "          print(tmp0, tmp1, tmp2, tmp3, sep=\"\\n\")\n",
        "          \n",
        "          #save history\n",
        "          self.history = {\"train_loss\": torch.tensor(train_loss_history), \"train_acc\": torch.tensor(train_acc_history), \n",
        "                          \"valid_loss\": torch.tensor(valid_loss_history), \"valid_acc\": torch.tensor(valid_acc_history)}\n",
        "           \n",
        "        \n",
        "  def generateConfusionMatrix(self):\n",
        "      fig=plt.figure(figsize = (12,7))\n",
        "      sns.heatmap(self.conf_matrix, annot=True, fmt='g', linewidths=.4, cbar=False)\n",
        "      tick_marks = np.arange(len(self.class_names))\n",
        "      plt.xticks(tick_marks, self.class_names, rotation=45)\n",
        "      plt.yticks(tick_marks, self.class_names, rotation=0)\n",
        "      plt.title(\"Confusion Matrix\")     \n",
        "\n",
        "  def getPerClassAccuracy(self):\n",
        "      per_class_accuracy = 100 * torch.diag(self.conf_matrix) / torch.sum(self.conf_matrix, 1)\n",
        "      tmp = {}\n",
        "      for i, x in enumerate(self.class_names):\n",
        "        tmp[x] = per_class_accuracy[i].item()\n",
        "      print(tmp)\n",
        "    \n",
        "  def showResults(self):\n",
        "      eps = range(0, len(self.history[\"train_loss\"].cpu()))\n",
        "        \n",
        "      sns.set_theme()\n",
        "      fig, ax = plt.subplots(1, 2, figsize=(14, 4))\n",
        "      fig.suptitle('Results')\n",
        "        \n",
        "      ax[0].plot(eps, smooth(self.history[\"train_loss\"].cpu()), 'g', label='Training Loss')\n",
        "      ax[0].plot(eps, smooth(self.history[\"valid_loss\"].cpu()), 'b', label='Valid Loss')\n",
        "      ax[0].set_title('Loss History')\n",
        "      ax[0].set(xlabel='Epochs', ylabel='Loss')\n",
        "      ax[0].legend()\n",
        "        \n",
        "      ax[1].plot(eps, smooth(self.history[\"train_acc\"].cpu()), 'g', label='Training Accuracy')\n",
        "      ax[1].plot(eps, smooth(self.history[\"valid_acc\"].cpu()), 'b', label='Valid Accuracy')\n",
        "      ax[1].set_title('Loss History')\n",
        "      ax[1].set(xlabel='Epochs', ylabel='Accuracy')\n",
        "      ax[1].legend()\n",
        "\n",
        "  def draw_voxels(self):\n",
        "      mesh = next(iter(self.train_dataloader))\n",
        "      mesh = mesh[0][0][0]\n",
        "        \n",
        "      ax = plt.figure(figsize=(10,10)).add_subplot(projection='3d')\n",
        "      ax.voxels(mesh, edgecolor='k')\n",
        "      plt.show()\n",
        "        \n",
        "  def test_on_missing_data(self, missing_rate=0.5):\n",
        "      test_accuracy = Accuracy(task='multiclass', num_classes=10)\n",
        "        \n",
        "      self.model.eval()\n",
        "      for x, y in self.test_dataloader:\n",
        "          x, y = x.to(self.device), y.to(self.device)\n",
        "            \n",
        "          idc = np.random.choice(32**3, size=(int(32**3*missing_rate)), replace=False)\n",
        "          idc_x = idc%32\n",
        "          idc_y = np.floor_divide(idc, 32)%32\n",
        "          idc_z = np.floor_divide(idc, 32*32)%32\n",
        "          x[:, :, idc_x, idc_y, idc_z] = 0\n",
        "            \n",
        "          pred = self.model(x)\n",
        "          test_accuracy.update(torch.argmax(pred, 1).cpu(), y.cpu())\n",
        "            \n",
        "      return test_accuracy.compute()\n",
        "    \n",
        "  def missing_data_test(self):\n",
        "      acc = []\n",
        "      delta = 200\n",
        "      eps = np.linspace(0,0.99,delta)\n",
        "      for x in eps:\n",
        "          tmp = self.test_on_missing_data(x)\n",
        "          acc.append(tmp)\n",
        "            \n",
        "            \n",
        "      sns.set_theme()\n",
        "      plt.figure(figsize=(8, 4))\n",
        "      plt.plot(eps, smooth(acc))\n",
        "      plt.title(\"Missing Data Test\", size=20, y=1.05)\n",
        "      plt.xlabel(\"missing point ratio\", size=15)\n",
        "      plt.ylabel(\"accuracy\", size=15)\n",
        "      plt.show()"
      ],
      "metadata": {
        "id": "hX_KJavxavhZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_hyperparameters = {\n",
        "    \"learning_rate\": 0.1,\n",
        "    \"sgd_momentum\": 0.1,\n",
        "    \"data_size\": 32,\n",
        "    \"epochs\": 30,\n",
        "    \"train_batch_size\": 64,\n",
        "    \"valid_batch_size\": 64\n",
        "}    \n",
        "\n",
        "trainer = VoxNet_Trainer(training_hyperparameters)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "HBhOIt8Emq1B",
        "outputId": "f67a534a-8495-424b-812c-97c885b05b87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62.359375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 1.4625989198684692: : 62it [01:14,  1.21s/it]\n",
            "15it [00:09,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  1 / 50\n",
            "time: 84.64 seconds\n",
            "train-loss: 1.81, train-acc: 39.94%\n",
            "valid-loss: 1.64, valid-acc: 36.23%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 1.3920692205429077: : 62it [01:15,  1.22s/it]\n",
            "15it [00:09,  1.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  2 / 50\n",
            "time: 84.83 seconds\n",
            "train-loss: 1.19, train-acc: 59.38%\n",
            "valid-loss: 1.68, valid-acc: 43.50%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.7336651086807251: : 62it [01:10,  1.14s/it]\n",
            "15it [00:09,  1.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  3 / 50\n",
            "time: 80.28 seconds\n",
            "train-loss: 0.98, train-acc: 66.81%\n",
            "valid-loss: 0.94, valid-acc: 67.29%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.6844720840454102: : 62it [01:11,  1.15s/it]\n",
            "15it [00:09,  1.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  4 / 50\n",
            "time: 80.96 seconds\n",
            "train-loss: 0.85, train-acc: 71.04%\n",
            "valid-loss: 0.79, valid-acc: 70.93%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.7400819659233093: : 62it [01:17,  1.24s/it]\n",
            "15it [00:10,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  5 / 50\n",
            "time: 87.24 seconds\n",
            "train-loss: 0.75, train-acc: 75.15%\n",
            "valid-loss: 0.72, valid-acc: 73.24%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.7304141521453857: : 62it [01:14,  1.20s/it]\n",
            "15it [00:09,  1.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  6 / 50\n",
            "time: 83.89 seconds\n",
            "train-loss: 0.72, train-acc: 77.07%\n",
            "valid-loss: 0.71, valid-acc: 73.46%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.5102857351303101: : 62it [01:11,  1.15s/it]\n",
            "15it [00:09,  1.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  7 / 50\n",
            "time: 80.52 seconds\n",
            "train-loss: 0.64, train-acc: 78.76%\n",
            "valid-loss: 1.04, valid-acc: 64.76%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.790799617767334: : 62it [01:13,  1.19s/it]\n",
            "15it [00:09,  1.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  8 / 50\n",
            "time: 83.35 seconds\n",
            "train-loss: 0.62, train-acc: 79.74%\n",
            "valid-loss: 0.86, valid-acc: 73.57%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.5448880791664124: : 62it [01:10,  1.14s/it]\n",
            "15it [00:09,  1.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  9 / 50\n",
            "time: 80.09 seconds\n",
            "train-loss: 0.60, train-acc: 80.47%\n",
            "valid-loss: 0.69, valid-acc: 77.31%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.6253417730331421: : 62it [01:10,  1.14s/it]\n",
            "15it [00:09,  1.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10 / 50\n",
            "time: 79.84 seconds\n",
            "train-loss: 0.59, train-acc: 81.43%\n",
            "valid-loss: 0.64, valid-acc: 78.63%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.5511234998703003: : 62it [01:13,  1.19s/it]\n",
            "15it [00:09,  1.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 11 / 50\n",
            "time: 83.29 seconds\n",
            "train-loss: 0.56, train-acc: 81.83%\n",
            "valid-loss: 0.58, valid-acc: 79.74%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.4368481934070587: : 62it [01:10,  1.14s/it]\n",
            "15it [00:09,  1.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 12 / 50\n",
            "time: 79.74 seconds\n",
            "train-loss: 0.52, train-acc: 83.49%\n",
            "valid-loss: 0.58, valid-acc: 79.96%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.7058241367340088: : 62it [01:10,  1.14s/it]\n",
            "15it [00:09,  1.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 13 / 50\n",
            "time: 79.76 seconds\n",
            "train-loss: 0.53, train-acc: 82.66%\n",
            "valid-loss: 0.62, valid-acc: 79.63%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.5069735050201416: : 62it [01:14,  1.20s/it]\n",
            "15it [00:09,  1.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 14 / 50\n",
            "time: 83.64 seconds\n",
            "train-loss: 0.49, train-acc: 82.96%\n",
            "valid-loss: 0.54, valid-acc: 81.28%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.47344011068344116: : 62it [01:10,  1.14s/it]\n",
            "15it [00:09,  1.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 15 / 50\n",
            "time: 80.21 seconds\n",
            "train-loss: 0.48, train-acc: 83.92%\n",
            "valid-loss: 0.58, valid-acc: 80.84%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.6753804683685303: : 62it [01:12,  1.17s/it]\n",
            "15it [00:09,  1.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 16 / 50\n",
            "time: 81.68 seconds\n",
            "train-loss: 0.47, train-acc: 85.38%\n",
            "valid-loss: 0.56, valid-acc: 80.07%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.5791807770729065: : 62it [01:13,  1.19s/it]\n",
            "15it [00:09,  1.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 17 / 50\n",
            "time: 83.13 seconds\n",
            "train-loss: 0.47, train-acc: 84.50%\n",
            "valid-loss: 0.56, valid-acc: 78.41%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.30037781596183777: : 62it [01:11,  1.15s/it]\n",
            "15it [00:09,  1.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 18 / 50\n",
            "time: 81.07 seconds\n",
            "train-loss: 0.43, train-acc: 85.46%\n",
            "valid-loss: 0.55, valid-acc: 82.05%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.4791198670864105: : 62it [01:15,  1.22s/it]\n",
            "15it [00:12,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 19 / 50\n",
            "time: 87.85 seconds\n",
            "train-loss: 0.45, train-acc: 85.08%\n",
            "valid-loss: 0.52, valid-acc: 80.95%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.3332473933696747: : 62it [01:15,  1.21s/it]\n",
            "15it [00:10,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 20 / 50\n",
            "time: 85.16 seconds\n",
            "train-loss: 0.43, train-acc: 85.64%\n",
            "valid-loss: 0.55, valid-acc: 80.62%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.6187281608581543: : 62it [01:14,  1.20s/it]\n",
            "15it [00:10,  1.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 21 / 50\n",
            "time: 85.23 seconds\n",
            "train-loss: 0.42, train-acc: 86.37%\n",
            "valid-loss: 0.51, valid-acc: 81.61%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.5525313019752502: : 62it [01:18,  1.27s/it]\n",
            "15it [00:09,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 22 / 50\n",
            "time: 88.31 seconds\n",
            "train-loss: 0.40, train-acc: 85.91%\n",
            "valid-loss: 0.55, valid-acc: 81.83%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.3570217788219452: : 62it [01:14,  1.20s/it]\n",
            "15it [00:10,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 23 / 50\n",
            "time: 84.48 seconds\n",
            "train-loss: 0.38, train-acc: 86.84%\n",
            "valid-loss: 0.50, valid-acc: 83.37%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.6301301717758179: : 62it [01:15,  1.22s/it]\n",
            "15it [00:09,  1.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 24 / 50\n",
            "time: 85.11 seconds\n",
            "train-loss: 0.38, train-acc: 87.22%\n",
            "valid-loss: 0.51, valid-acc: 82.16%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.3788754343986511: : 62it [01:14,  1.20s/it]\n",
            "15it [00:09,  1.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 25 / 50\n",
            "time: 83.54 seconds\n",
            "train-loss: 0.38, train-acc: 87.95%\n",
            "valid-loss: 0.48, valid-acc: 84.36%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.2792584002017975: : 62it [01:11,  1.15s/it]\n",
            "15it [00:09,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 26 / 50\n",
            "time: 81.19 seconds\n",
            "train-loss: 0.38, train-acc: 87.25%\n",
            "valid-loss: 0.50, valid-acc: 83.59%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.36952468752861023: : 62it [01:13,  1.19s/it]\n",
            "15it [00:09,  1.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 27 / 50\n",
            "time: 83.24 seconds\n",
            "train-loss: 0.37, train-acc: 87.88%\n",
            "valid-loss: 0.46, valid-acc: 83.48%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.5413928627967834: : 62it [01:14,  1.20s/it]\n",
            "15it [00:09,  1.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 28 / 50\n",
            "time: 83.77 seconds\n",
            "train-loss: 0.36, train-acc: 87.45%\n",
            "valid-loss: 0.50, valid-acc: 83.81%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train loss: 0.3590024411678314: : 10it [00:12,  1.22s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-27d7127deba7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVoxNet_Trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_hyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-a9f8b0d7ef50>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m               \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# torch.Size([256, 10])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m               \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m               \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-4fc97508a4a1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             )\n\u001b[0;32m--> 608\u001b[0;31m         return F.conv3d(\n\u001b[0m\u001b[1;32m    609\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def smooth(x, w=0):\n",
        "    last = x[0]\n",
        "    smoothed = []\n",
        "    for point in x:\n",
        "      smoothed_val = w * last + (1 - w) * point\n",
        "      smoothed.append(smoothed_val)\n",
        "      ast = smoothed_val\n",
        "          \n",
        "    return smoothed\n",
        "\n",
        "trainer.showResults()"
      ],
      "metadata": {
        "id": "N7DHiwXimwKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.generateConfusionMatrix()"
      ],
      "metadata": {
        "id": "yr5CE5Zjw9Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.getPerClassAccuracy()"
      ],
      "metadata": {
        "id": "zTsndYBB95vT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.missing_data_test()"
      ],
      "metadata": {
        "id": "s30abd-s2seu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.draw_voxels()"
      ],
      "metadata": {
        "id": "3vp-GeB2xdit"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}